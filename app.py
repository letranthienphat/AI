import streamlit as st
import time
import json
import psutil
from datetime import datetime
from openai import OpenAI
import google.generativeai as genai
import streamlit.components.v1 as components

# --- 1. C·∫§U H√åNH H·ªÜ TH·ªêNG ---
st.set_page_config(page_title="NEXUS V68.0", layout="wide", page_icon="üé®")

# L·∫•y Keys t·ª´ Secrets
GROQ_KEYS = st.secrets.get("GROQ_KEYS", [])
GEMINI_KEY = st.secrets.get("GEMINI_KEY", "")

# Kh·ªüi t·∫°o Session State
if 'chat_log' not in st.session_state: st.session_state.chat_log = []
if 'bg_url' not in st.session_state: st.session_state.bg_url = "https://images.unsplash.com/photo-1614850523296-d8c1af93d400?q=80&w=2070"
if 'auto_scroll' not in st.session_state: st.session_state.auto_scroll = True

# --- 2. GIAO DI·ªÜN SI√äU T∆Ø∆†NG PH·∫¢N (ULTRA CONTRAST CSS) ---
def apply_advanced_ui():
    bg = st.session_state.bg_url
    st.markdown(f"""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;700&family=Fira+Code&display=swap');
    
    .stApp {{
        background: linear-gradient(rgba(0,0,0,0.85), rgba(0,0,0,0.85)), url("{bg}");
        background-size: cover;
        background-attachment: fixed;
    }}

    /* Khung chat si√™u t∆∞∆°ng ph·∫£n - Ch·ªØ tr·∫Øng tinh tr√™n n·ªÅn ƒë·∫∑c */
    div[data-testid="stChatMessage"] {{
        background: rgba(10, 15, 25, 0.98) !important;
        border: 2px solid #00f2ff;
        border-radius: 12px !important;
        box-shadow: 0 10px 30px rgba(0,0,0,0.8);
        padding: 20px !important;
    }}
    
    .stMarkdown p, .stMarkdown h1, .stMarkdown h2 {{
        color: #FFFFFF !important;
        font-family: 'Inter', sans-serif;
        font-weight: 500;
        text-shadow: 2px 2px 4px #000000;
    }}

    /* Thanh Input c·ªë ƒë·ªãnh kh√¥ng nh·∫£y */
    .stChatFloatingInputContainer {{
        background: rgba(0,0,0,0.9) !important;
        border-top: 2px solid #00f2ff !important;
        padding: 15px !important;
    }}

    /* Icon Clickable Style */
    .icon-btn {{
        display: inline-block;
        padding: 10px 20px;
        margin: 5px;
        background: rgba(0, 242, 255, 0.1);
        border: 1px solid #00f2ff;
        border-radius: 8px;
        color: #00f2ff;
        cursor: pointer;
        transition: 0.3s;
        text-decoration: none;
        font-weight: bold;
    }}
    .icon-btn:hover {{
        background: #00f2ff;
        color: #000;
        box-shadow: 0 0 20px #00f2ff;
    }}

    /* Settings Box */
    .settings-panel {{
        background: rgba(255, 255, 255, 0.05);
        border: 1px solid rgba(255, 255, 255, 0.2);
        padding: 20px;
        border-radius: 15px;
        backdrop-filter: blur(10px);
    }}
    </style>
    """, unsafe_allow_html=True)

apply_advanced_ui()

# --- 3. JAVASCRIPT: AUTO-SCROLL ---
def inject_auto_scroll():
    components.html(
        """<script>
        window.parent.document.querySelector(".main").scrollTo({
            top: window.parent.document.querySelector(".main").scrollHeight,
            behavior: 'smooth'
        });
        </script>""", height=0
    )

# --- 4. H√ÄM AI & LOGIC ---
def get_ai_response(prompt):
    # G·ª≠i TO√ÄN B·ªò l·ªãch s·ª≠ vƒ©nh c·ª≠u
    history = [{"role": m["role"], "content": m["content"]} for m in st.session_state.chat_log]
    history.append({"role": "user", "content": prompt})
    
    # Routing Groq 1-4 -> Gemini
    for i, key in enumerate(GROQ_KEYS):
        try:
            client = OpenAI(api_key=key, base_url="https://api.groq.com/openai/v1")
            return client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=history,
                stream=True
            ), f"Groq Node {i+1}"
        except: continue
        
    try:
        genai.configure(api_key=GEMINI_KEY)
        model = genai.GenerativeModel('gemini-1.5-flash')
        gem_hist = [{"role": "user" if m["role"] == "user" else "model", "parts": [m["content"]]} for m in history[:-1]]
        chat = model.start_chat(history=gem_hist)
        return chat.send_message(prompt, stream=True), "Gemini Ultra"
    except: return None, None

# --- 5. GIAO DI·ªÜN ƒêI·ªÄU KHI·ªÇN ---
def main():
    # SIDEBAR: DANH S√ÅCH PHI√äN & TR·∫†NG TH√ÅI
    with st.sidebar:
        st.title("üóÇÔ∏è CH·ªà HUY NEXUS")
        st.info("H·ªá th·ªëng ƒë√£ lo·∫°i b·ªè Monitor RAM/CPU ƒë·ªÉ t·ªëi ∆∞u t·ªëc ƒë·ªô.")
        if st.button("üóëÔ∏è X√ìA B·ªò NH·ªö T·∫†M"):
            st.session_state.chat_log = []
            st.rerun()

    # M√ÄN H√åNH CH√çNH
    col_main, col_set = st.columns([3, 1])

    with col_set:
        st.markdown("### ‚öôÔ∏è C√ÄI ƒê·∫∂T H·ªÜ TH·ªêNG")
        with st.container():
            st.markdown("<div class='settings-panel'>", unsafe_allow_html=True)
            # T√≠nh nƒÉng ƒë·ªïi h√¨nh n·ªÅn qua URL
            new_bg = st.text_input("üñºÔ∏è D√°n URL h√¨nh n·ªÅn m·ªõi:", value=st.session_state.bg_url)
            if st.button("C·∫¨P NH·∫¨T H√åNH N·ªÄN"):
                st.session_state.bg_url = new_bg
                st.rerun()
            
            st.divider()
            st.markdown("**L·ªánh nhanh (Click Icon):**")
            # Icon Clickable
            if st.button("üîç T√≥m t·∫Øt v·ª• √°n", use_container_width=True):
                process_chat("H√£y t√≥m t·∫Øt l·∫°i to√†n b·ªô th√¥ng tin quan tr·ªçng t·ª´ ƒë·∫ßu ƒë·∫øn gi·ªù.")
            if st.button("üß™ Ph√¢n t√≠ch b·∫±ng ch·ª©ng", use_container_width=True):
                process_chat("D·ª±a tr√™n l·ªãch s·ª≠ h·ªôi tho·∫°i, h√£y ph√¢n t√≠ch c√°c b·∫±ng ch·ª©ng hi·ªán c√≥.")
            if st.button("üö® Xu·∫•t b√°o c√°o", use_container_width=True):
                process_chat("Vi·∫øt m·ªôt b·∫£n b√°o c√°o t·ªïng k·∫øt v·ª• √°n chuy√™n nghi·ªáp.")
            st.markdown("</div>", unsafe_allow_html=True)

    with col_main:
        st.title("ü§ñ NEURAL TERMINAL")
        
        # V√πng Chat
        chat_area = st.container()
        with chat_area:
            for msg in st.session_state.chat_log:
                with st.chat_message(msg["role"]):
                    st.markdown(msg["content"])

        # Nh·∫≠p li·ªáu (C·ªë ƒë·ªãnh ·ªü ƒë√°y)
        if prompt := st.chat_input("Nh·∫≠p l·ªánh ƒëi·ªÅu khi·ªÉn..."):
            process_chat(prompt)

def process_chat(prompt):
    st.session_state.chat_log.append({"role": "user", "content": prompt})
    with st.chat_message("user"): st.markdown(prompt)

    with st.chat_message("assistant"):
        res_box = st.empty()
        full_res = ""
        stream, source = get_ai_response(prompt)
        
        if stream:
            if st.session_state.auto_scroll: inject_auto_scroll()
            
            for chunk in stream:
                content = chunk.choices[0].delta.content if "Groq" in source else chunk.text
                if content:
                    full_res += content
                    res_box.markdown(full_res + "‚ñà")
            
            res_box.markdown(full_res)
            st.caption(f"‚ö° Node: {source} | Tr√≠ nh·ªõ: To√†n di·ªán")
            st.session_state.chat_log.append({"role": "assistant", "content": full_res})
            st.rerun()
        else:
            st.error("üÜò Server AI kh√¥ng ph·∫£n h·ªìi.")

if __name__ == "__main__":
    main()
