import streamlit as st
from openai import OpenAI
from gtts import gTTS
from io import BytesIO
import qrcode
from streamlit_mic_recorder import mic_recorder
import os

# --- Cáº¤U HÃŒNH ---
st.set_page_config(page_title="AI Live Pro", layout="wide", page_icon="ğŸ™ï¸")

# CSS Ä‘á»ƒ lÃ m giao diá»‡n gá»n gÃ ng hÆ¡n
st.markdown("""
    <style>
    .main { background-color: #f5f7f9; }
    .stButton>button { width: 100%; border-radius: 20px; }
    .chat-bubble { padding: 10px; border-radius: 15px; margin-bottom: 10px; }
    </style>
    """, unsafe_allow_html=True)

GROQ_API_KEY = st.secrets.get("GROQ_API_KEY", "")

# Khá»Ÿi táº¡o Session
if "messages" not in st.session_state: st.session_state.messages = []
if "speech_text" not in st.session_state: st.session_state.speech_text = ""
if "interrupt" not in st.session_state: st.session_state.interrupt = False

# --- HÃ€M TTS Vá»šI Tá»C Äá»˜ ---
def text_to_speech(text, speed=1.0):
    tts = gTTS(text=text, lang='vi')
    fp = BytesIO()
    tts.write_to_fp(fp)
    return fp.getvalue()

# --- SIDEBAR Gá»ŒN GÃ€NG ---
with st.sidebar:
    st.title("ğŸ™ï¸ AI Live Hub")
    speed = st.slider("Tá»‘c Ä‘á»™ Ä‘á»c cá»§a AI", 0.5, 2.0, 1.0, 0.1)
    live_mode = st.toggle("Cháº¿ Ä‘á»™ Live (Tá»± pháº£n há»“i)", value=True)
    
    st.divider()
    if st.button("ğŸ“„ Xuáº¥t mÃ£ QR"):
        full_text = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.messages])
        # (Logic táº¡o QR giá»¯ nguyÃªn nhÆ° báº£n cÅ©)
        st.toast("ÄÃ£ táº¡o QR bÃªn dÆ°á»›i mÃ n hÃ¬nh!")

    if st.button("ğŸ›‘ NGáº®T Lá»œI AI"):
        st.session_state.interrupt = True
        st.rerun()

# --- GIAO DIá»†N CHAT CHÃNH ---
st.title("ğŸ¤– Trá»£ lÃ½ Live")

# Hiá»ƒn thá»‹ há»™i thoáº¡i
chat_container = st.container(height=400)
with chat_container:
    for i, m in enumerate(st.session_state.messages):
        with st.chat_message(m["role"]):
            st.markdown(m["content"])
            if m["role"] == "assistant" and not st.session_state.interrupt:
                st.audio(text_to_speech(m["content"], speed), format="audio/mp3")

# --- KHU Vá»°C NHáº¬P LIá»†U (STT & EDIT) ---
st.write("---")
col1, col2, col3 = st.columns([1, 7, 1])

with col1:
    # NÃºt thu Ã¢m (CÃ³ tÃ­ch há»£p khá»­ nhiá»…u tá»« pháº§n cá»©ng trÃ¬nh duyá»‡t)
    audio_record = mic_recorder(start_prompt="ğŸ¤ NÃ³i", stop_prompt="âœ… Xong", key='mic_pro')

with col2:
    # HIá»†N NHá»®NG GÃŒ Dá»ŠCH ÄÆ¯á»¢C LÃŠN ÄÃ‚Y Äá»‚ CHá»ˆNH Sá»¬A
    user_input = st.text_input("Ná»™i dung tin nháº¯n:", value=st.session_state.speech_text, key="chat_input_text")

with col3:
    send_btn = st.button("ğŸš€ Gá»­i")

# Xá»­ lÃ½ khi cÃ³ giá»ng nÃ³i má»›i
if audio_record:
    # DÃ¹ng Whisper Ä‘á»ƒ chuyá»ƒn giá»ng nÃ³i thÃ nh vÄƒn báº£n (STT)
    client = OpenAI(api_key=GROQ_API_KEY, base_url="https://api.groq.com/openai/v1")
    
    # LÆ°u táº¡m file Ã¢m thanh Ä‘á»ƒ dá»‹ch
    with open("temp_audio.wav", "wb") as f:
        f.write(audio_record['bytes'])
    
    with open("temp_audio.wav", "rb") as audio_file:
        transcript = client.audio.transcriptions.create(
            model="whisper-large-v3", 
            file=audio_file,
            language="vi"
        )
    
    # ÄÆ°a káº¿t quáº£ dá»‹ch Ä‘Æ°á»£c vÃ o Ã´ nháº­p liá»‡u Ä‘á»ƒ ngÆ°á»i dÃ¹ng sá»­a
    st.session_state.speech_text = transcript.text
    st.rerun()

# --- LOGIC Gá»¬I VÃ€ PHáº¢N Há»’I ---
if send_btn and user_input:
    st.session_state.interrupt = False # Reset tráº¡ng thÃ¡i ngáº¯t lá»i
    st.session_state.messages.append({"role": "user", "content": user_input})
    st.session_state.speech_text = "" # XÃ³a Ã´ nháº­p sau khi gá»­i
    
    with st.chat_message("assistant"):
        res_area = st.empty()
        full_res = ""
        client = OpenAI(api_key=GROQ_API_KEY, base_url="https://api.groq.com/openai/v1")
        
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages],
            stream=True
        )
        
        for chunk in response:
            if st.session_state.interrupt: break # Kiá»ƒm tra nÃºt ngáº¯t lá»i
            if chunk.choices[0].delta.content:
                full_res += chunk.choices[0].delta.content
                res_area.markdown(full_res + "â–Œ")
        
        res_area.markdown(full_res)
        st.session_state.messages.append({"role": "assistant", "content": full_res})
        st.rerun()
