import streamlit as st
from openai import OpenAI
from gtts import gTTS
from io import BytesIO
from streamlit_mic_recorder import mic_recorder
import qrcode
import base64
from langdetect import detect
import re
import json

# --- 1. Cáº¤U HÃŒNH UI & CSS ---
st.set_page_config(page_title="Nexus v18 Fixed", layout="wide", page_icon="ğŸ›¡ï¸")

st.markdown("""
    <style>
    .spotlight-active { border: 4px solid #007bff !important; box-shadow: 0 0 30px rgba(0,123,255,0.5); background: #f0f7ff !important; z-index: 999; }
    .dimmed { opacity: 0.2; filter: blur(2px); pointer-events: none; transition: 0.5s; }
    .floating-guide {
        position: fixed; top: 15%; left: 50%; transform: translateX(-50%);
        background: white; padding: 20px; border-radius: 15px;
        box-shadow: 0 10px 40px rgba(0,0,0,0.3); z-index: 1000;
        width: 90%; max-width: 450px; border-top: 5px solid #007bff;
    }
    .stApp { background-color: #ffffff; }
    </style>
    """, unsafe_allow_html=True)

# --- 2. HÃ€M Há»– TRá»¢ ---
def speak_js(text, speed, lang):
    clean = text.replace('"', "'").replace('\n', ' ')
    return f"<script>window.speechSynthesis.cancel(); var m=new SpeechSynthesisUtterance('{clean}'); m.lang='{lang}'; m.rate={speed}; window.speechSynthesis.speak(m);</script>"

def get_lang_code(text):
    try:
        l = detect(text)
        mapping = {"vi":"vi-VN", "en":"en-US", "ja":"ja-JP", "ko":"ko-KR"}
        return mapping.get(l, "vi-VN")
    except: return "vi-VN"

# --- 3. KHá»I Táº O STATE (QUAN TRá»ŒNG) ---
if "messages" not in st.session_state: st.session_state.messages = []
if "suggestions" not in st.session_state: st.session_state.suggestions = ["ChÃ o báº¡n", "TÃ­nh nÄƒng má»›i", "Ká»ƒ chuyá»‡n"]
if "guide_step" not in st.session_state: st.session_state.guide_step = 0 
if "remember_choice" not in st.session_state: st.session_state.remember_choice = False
if "onboarding_done" not in st.session_state: st.session_state.onboarding_done = False

client = OpenAI(api_key=st.secrets["GROQ_API_KEY"], base_url="https://api.groq.com/openai/v1")

# --- 4. HÃ€M Xá»¬ LÃ AI ---
def process_ai(user_input):
    st.session_state.messages.append({"role": "user", "content": user_input})
    lang = get_lang_code(user_input)
    with st.chat_message("assistant"):
        p = st.empty(); full = ""
        res = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages],
            stream=True
        )
        for chunk in res:
            if chunk.choices[0].delta.content:
                full += chunk.choices[0].delta.content
                p.markdown(full + "â–Œ")
        p.markdown(full)
        st.session_state.messages.append({"role": "assistant", "content": full})
        if st.session_state.get("auto_read", True):
            st.components.v1.html(speak_js(full, st.session_state.v_speed, lang), height=0)
        try:
            s_res = client.chat.completions.create(model="llama-3.1-8b-instant", messages=[{"role": "user", "content": f"Táº¡o 4 cÃ¢u há»i tiáº¿p ná»‘i ngáº¯n cho: '{full[:100]}', ngÄƒn cÃ¡ch báº±ng dáº¥u pháº©y."}])
            st.session_state.suggestions = [s.strip() for s in s_res.choices[0].message.content.split(',') if s.strip()][:4]
        except: pass

# --- 5. SIDEBAR: FULL OPTION ---
with st.sidebar:
    st.title("ğŸ›¡ï¸ Nexus Terminal")
    if st.button("ğŸ“– Cháº¡y láº¡i hÆ°á»›ng dáº«n máº«u", use_container_width=True):
        st.session_state.onboarding_done = False
        st.session_state.guide_step = 1
        st.rerun()
    
    st.divider()
    st.session_state.v_speed = st.slider("Tá»‘c Ä‘á»™ Ä‘á»c", 0.5, 2.0, 1.1)
    st.session_state.auto_read = st.toggle("Tá»± Ä‘á»™ng Ä‘á»c", value=True)
    
    st.divider()
    st.subheader("ğŸ’¾ Dá»¯ liá»‡u & LÆ°u trá»¯")
    chat_data = json.dumps(st.session_state.messages, ensure_ascii=False)
    st.download_button("ğŸ“¤ Xuáº¥t file lÆ°u trá»¯ (.json)", data=chat_data, file_name="nexus_chat.json", use_container_width=True)
    
    up = st.file_uploader("ğŸ“¥ Nháº­p file cÅ©", type="json")
    if up:
        if st.button("ğŸ”„ KhÃ´i phá»¥c dá»¯ liá»‡u"):
            st.session_state.messages = json.loads(up.getvalue().decode("utf-8"))
            st.rerun()

    if st.button("ğŸ—‘ï¸ XÃ³a sáº¡ch há»™i thoáº¡i", use_container_width=True):
        st.session_state.messages = []; st.rerun()

# --- 6. GIAO DIá»†N CHÃNH & TOUR HÆ¯á»šNG DáºªN ---
st.title("AI Nexus v18 ğŸ›¡ï¸")

# MÃ n hÃ¬nh há»i Onboarding (chá»‰ hiá»‡n 1 láº§n náº¿u khÃ´ng chá»n remember)
if not st.session_state.onboarding_done and st.session_state.guide_step == 0:
    with st.container():
        st.info("ğŸ‘‹ ChÃ o báº¡n! Báº¡n muá»‘n xem hÆ°á»›ng dáº«n tÆ°Æ¡ng tÃ¡c máº«u hay báº¯t Ä‘áº§u ngay?")
        rem = st.checkbox("Ghi nhá»› lá»±a chá»n nÃ y (LÆ°u vÃ o bá»™ nhá»› phiÃªn)")
        c1, c2 = st.columns(2)
        if c1.button("âœ¨ Xem hÆ°á»›ng dáº«n máº«u"):
            st.session_state.onboarding_done = rem
            st.session_state.messages = [{"role":"user","content":"DÃ¹ng thá»­ máº«u"},{"role":"assistant","content":"ÄÃ¢y lÃ  tin nháº¯n máº«u. HÃ£y nháº¥n cÃ¡c nÃºt ğŸ”Š Nghe, ğŸ“¥ Táº£i bÃªn dÆ°á»›i Ä‘á»ƒ thá»­!"}]
            st.session_state.guide_step = 1
            st.rerun()
        if c2.button("ğŸš€ Báº¯t Ä‘áº§u ngay"):
            st.session_state.onboarding_done = rem
            st.session_state.guide_step = 0
            st.rerun()

# Báº£ng hÆ°á»›ng dáº«n ná»•i (Floating Guide)
if 1 <= st.session_state.guide_step <= 4:
    guides = {1: "ğŸ¤ **BÆ¯á»šC 1:** DÃ¹ng Mic hoáº·c Chat Input bÃªn dÆ°á»›i Ä‘á»ƒ nháº­p liá»‡u.",
              2: "ğŸ”Š **BÆ¯á»šC 2:** Thá»­ nháº¥n nÃºt Nghe/Táº£i á»Ÿ tin nháº¯n máº«u nÃ y!",
              3: "ğŸ’¡ **BÆ¯á»šC 3:** CÃ¡c nÃºt gá»£i Ã½ giÃºp báº¡n há»i nhanh hÆ¡n.",
              4: "âš™ï¸ **BÆ¯á»šC 4:** CÃ i Ä‘áº·t tá»‘c Ä‘á»™ vÃ  LÆ°u trá»¯ á»Ÿ Sidebar."}
    st.markdown(f'<div class="floating-guide"><h4>ğŸ¯ HÆ°á»›ng dáº«n {st.session_state.guide_step}/4</h4><p>{guides[st.session_state.guide_step]}</p></div>', unsafe_allow_html=True)
    if st.button(f"Xong bÆ°á»›c {st.session_state.guide_step} â¡ï¸", use_container_width=True):
        st.session_state.guide_step = (st.session_state.guide_step + 1) if st.session_state.guide_step < 4 else 0
        st.rerun()

# --- HIá»‚N THá»Š CHAT (FIXED KEYS) ---
for i, m in enumerate(st.session_state.messages):
    # Highlight náº¿u Ä‘ang á»Ÿ bÆ°á»›c 2
    step_style = "spotlight-active" if (st.session_state.guide_step == 2 and m["role"] == "assistant") else ("dimmed" if st.session_state.guide_step not in [0,2] else "")
    st.markdown(f'<div class="{step_style}">', unsafe_allow_html=True)
    with st.chat_message(m["role"]):
        st.markdown(m["content"])
        if m["role"] == "assistant":
            c1, c2, c3 = st.columns(3)
            with c1: # Key duy nháº¥t: v_ + index
                if st.button("ğŸ”Š Nghe", key=f"v_btn_{i}"):
                    st.components.v1.html(speak_js(m["content"], st.session_state.v_speed, get_lang_code(m["content"])), height=0)
            with c2: # Key duy nháº¥t: d_ + index
                tts = gTTS(text=m["content"][:100], lang="vi")
                b = BytesIO(); tts.write_to_fp(b); b64 = base64.b64encode(b.getvalue()).decode()
                st.markdown(f'<a href="data:audio/mp3;base64,{b64}" download="voice.mp3"><button style="width:100%; border-radius:10px; border:1px solid #ddd; padding:5px; cursor:pointer;" id="d_btn_{i}">ğŸ“¥ Táº£i</button></a>', unsafe_allow_html=True)
            with c3: # Key duy nháº¥t: q_ + index
                if st.button("ğŸ“± QR", key=f"q_btn_{i}"):
                    qr = qrcode.make(m["content"][:300]); buf = BytesIO(); qr.save(buf, format="PNG"); st.image(buf, width=100)
    st.markdown('</div>', unsafe_allow_html=True)

# --- NÃšT Gá»¢I Ã (FIXED KEYS) ---
st.write("---")
sug_style = "spotlight-active" if st.session_state.guide_step == 3 else ("dimmed" if st.session_state.guide_step not in [0,3] else "")
st.markdown(f'<div class="{sug_style}">', unsafe_allow_html=True)
if st.session_state.suggestions:
    cols = st.columns(len(st.session_state.suggestions))
    for idx, sug in enumerate(st.session_state.suggestions):
        # Key cá»±c ká»³ an toÃ n: s_ + hash ná»™i dung + index
        if cols[idx].button(sug.strip(), key=f"sug_atomic_{idx}_{hash(sug)}", use_container_width=True):
            process_ai(sug); st.rerun()
st.markdown('</div>', unsafe_allow_html=True)

# --- INPUT AREA ---
st.write("<br><br><br><br>", unsafe_allow_html=True)
in_style = "spotlight-active" if st.session_state.guide_step == 1 else ("dimmed" if st.session_state.guide_step not in [0,1] else "")
st.markdown(f'<div class="{in_style}" style="position:fixed; bottom:0; width:100%; background:white; padding:10px; left:0;">', unsafe_allow_html=True)
c_m, c_i = st.columns([1, 6])
with c_m: audio = mic_recorder(start_prompt="ğŸ¤", stop_prompt="â¹ï¸", key='mic_v18')
if audio:
    transcript = client.audio.transcriptions.create(model="whisper-large-v3-turbo", file=("v.wav", audio['bytes']))
    process_ai(transcript.text); st.rerun()
inp = st.chat_input("Nháº­p tin nháº¯n táº¡i Ä‘Ã¢y...")
if inp: process_ai(inp); st.rerun()
st.markdown('</div>', unsafe_allow_html=True)
