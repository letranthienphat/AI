import streamlit as st
from openai import OpenAI
import google.generativeai as genai
import time

# --- 1. C·∫§U H√åNH H·ªÜ TH·ªêNG ---
st.set_page_config(page_title="Nexus OS V55.5", layout="wide")

# Kh·ªüi t·∫°o b·ªô nh·ªõ v√† c·∫•u h√¨nh
if 'chat_log' not in st.session_state: st.session_state.chat_log = []
if 'bg' not in st.session_state: st.session_state.bg = "https://images.unsplash.com/photo-1618005182384-a83a8bd57fbe?q=80&w=1964"

# --- 2. GIAO DI·ªÜN T∆Ø∆†NG PH·∫¢N SI√äU C·∫§P ---
st.markdown(f"""
    <style>
    .stApp {{
        background: linear-gradient(rgba(0,0,0,0.75), rgba(0,0,0,0.75)), url("{st.session_state.bg}");
        background-size: cover;
    }}
    /* Khung chat Glassmorphism ƒë·ªô s√°ng cao */
    .stChatMessage {{
        background: rgba(25, 30, 40, 0.95) !important;
        border: 1px solid #00d2ff;
        box-shadow: 0 8px 32px 0 rgba(0, 0, 0, 0.8);
    }}
    /* Ch·ªØ si√™u r√µ */
    .stMarkdown p, .stMarkdown h1, .stMarkdown h2, .stMarkdown h3 {{
        color: #FFFFFF !important;
        font-weight: 500;
        text-shadow: 1px 1px 2px #000000;
    }}
    /* Thanh nh·∫≠p li·ªáu n·ªïi b·∫≠t */
    .stChatInputContainer {{ border-top: 2px solid #00d2ff !important; }}
    </style>
    """, unsafe_allow_html=True)

# --- 3. L√ïI ƒêI·ªÄU PH·ªêI API (SMART-CHAINING) ---
def get_ai_response(prompt):
    """C∆° ch·∫ø b·∫≠c thang: Groq 1 -> 2 -> 3 -> Gemini"""
    keys = st.secrets["GROQ_KEYS"] # Gi·∫£ s·ª≠ b·∫°n c√≥ 3-4 keys trong danh s√°ch n√†y
    
    # Th·ª≠ t·ª´ng Key Groq theo th·ª© t·ª± ∆∞u ti√™n 1, 2, 3...
    for i, key in enumerate(keys):
        try:
            client = OpenAI(api_key=key, base_url="https://api.groq.com/openai/v1")
            response = client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": "user", "content": prompt}],
                stream=True,
                timeout=10 # N·∫øu ph·∫£n h·ªìi qu√° ch·∫≠m th√¨ chuy·ªÉn key
            )
            return response, f"Groq Key {i+1}"
        except Exception as e:
            continue # Th·ª≠ key ti·∫øp theo n·∫øu l·ªói ho·∫∑c h·∫øt l∆∞·ª£t (Rate Limit)

    # D·ª± ph√≤ng cu·ªëi c√πng: Gemini
    try:
        genai.configure(api_key=st.secrets["GEMINI_KEY"])
        model = genai.GenerativeModel('gemini-1.5-flash')
        return model.generate_content(prompt, stream=True), "Gemini (Backup)"
    except Exception as e:
        return None, f"T·∫•t c·∫£ API ƒë·ªÅu l·ªói: {str(e)}"

# --- 4. GIAO DI·ªÜN CH√çNH ---
def main():
    with st.sidebar:
        st.title("üí† NEXUS CORE")
        st.write("Phi√™n b·∫£n: **V55.5 (Hyper)**")
        st.divider()
        if st.button("üóëÔ∏è D·ªçn s·∫°ch Terminal"):
            st.session_state.chat_log = []
            st.rerun()
        st.info("üí° M·∫πo: Nh·∫Øn li√™n t·ª•c ƒë·ªÉ ki·ªÉm tra kh·∫£ nƒÉng chuy·ªÉn t·∫ßng API.")

    st.title("ü§ñ Neural Terminal")

    # Hi·ªÉn th·ªã Chat
    for msg in st.session_state.chat_log:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # G·ª£i √Ω c√¢u tr·∫£ l·ªùi ch·ªß ƒë·ªông
    if st.session_state.chat_log:
        c1, c2, c3 = st.columns(3)
        if c1.button("üîÑ Gi·∫£i th√≠ch th√™m"): process_chat("H√£y gi·∫£i th√≠ch chi ti·∫øt h∆°n v·ªÅ v·∫•n ƒë·ªÅ n√†y.")
        if c2.button("üìù T√≥m t·∫Øt √Ω ch√≠nh"): process_chat("T√≥m t·∫Øt l·∫°i nh·ªØng g√¨ ch√∫ng ta v·ª´a th·∫£o lu·∫≠n.")
        if c3.button("üé® V·∫Ω minh h·ªça"): process_chat("/draw m·ªôt h√¨nh ·∫£nh minh h·ªça cho n·ªôi dung n√†y.")

    # Input ng∆∞·ªùi d√πng
    if p := st.chat_input("Nh·∫≠p tin nh·∫Øn..."):
        process_chat(p)

def process_chat(user_input):
    st.session_state.chat_log.append({"role": "user", "content": user_input})
    
    with st.chat_message("assistant"):
        res_stream, source = get_ai_response(user_input)
        
        if res_stream:
            placeholder = st.empty()
            full_content = ""
            
            # X·ª≠ l√Ω streaming t√πy theo ngu·ªìn
            for chunk in res_stream:
                content = ""
                if "Groq" in source:
                    content = chunk.choices[0].delta.content or ""
                else:
                    content = chunk.text
                
                full_content += content
                placeholder.markdown(full_content + "‚ñå")
            
            placeholder.markdown(full_content)
            st.caption(f"‚ö° Ngu·ªìn: {source}")
            st.session_state.chat_log.append({"role": "assistant", "content": full_content})
        else:
            st.error("C·∫°n ki·ªát t√†i nguy√™n API. Vui l√≤ng th·ª≠ l·∫°i sau.")

if __name__ == "__main__":
    main()
