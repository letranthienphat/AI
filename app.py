import streamlit as st
import os
import json
import time
import psutil
import random
from datetime import datetime
from openai import OpenAI
import google.generativeai as genai

# --- 1. Há»† THá»NG QUáº¢N LÃ Cáº¤U HÃŒNH & Báº¢O Máº¬T ---
st.set_page_config(page_title="NEXUS V62.0 ARCHIVE", layout="wide", page_icon="ğŸ’¾")

# Kiá»ƒm tra API Keys tá»« Secrets
try:
    GROQ_KEYS = st.secrets["GROQ_KEYS"]
    GEMINI_KEY = st.secrets["GEMINI_KEY"]
except Exception as e:
    st.error("âŒ Cáº¤U HÃŒNH THIáº¾U: Vui lÃ²ng kiá»ƒm tra má»¥c Secrets trÃªn Streamlit Cloud.")
    st.stop()

# --- 2. KHá»I Táº O Bá»˜ NHá»š VÄ¨NH Cá»¬U (SESSION STATE) ---
if 'chat_sessions' not in st.session_state: st.session_state.chat_sessions = {}
if 'current_session_id' not in st.session_state: st.session_state.current_session_id = "Default_Node"
if 'chat_log' not in st.session_state: st.session_state.chat_log = []
if 'session_name' not in st.session_state: st.session_state.session_name = "Cuá»™c há»™i thoáº¡i má»›i"
if 'terminal_logs' not in st.session_state: st.session_state.terminal_logs = []

# --- 3. GIAO DIá»†N TERMINAL Äá»˜C QUYá»€N (CSS) ---
st.markdown(f"""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700&family=Source+Code+Pro:wght@300;500&display=swap');
    
    body {{ background-color: #050505; color: #00f2ff; }}
    .stApp {{
        background: radial-gradient(circle at 50% 50%, #0a1118 0%, #000000 100%);
    }}
    
    /* Khung Chat High-Contrast */
    [data-testid="stChatMessage"] {{
        background: rgba(0, 20, 30, 0.8) !important;
        border: 1px solid #00f2ff33;
        border-radius: 10px !important;
        box-shadow: 0 0 15px rgba(0, 242, 255, 0.1);
        color: white !important;
    }}
    
    /* Chá»¯ Neon */
    h1, h2, h3 {{
        font-family: 'Orbitron', sans-serif;
        color: #00f2ff !important;
        text-shadow: 0 0 10px #00f2ff;
    }}
    
    .stMarkdown p {{
        font-family: 'Source Code Pro', monospace;
        color: #e0faff !important;
        font-size: 1.05rem;
    }}

    /* Sidebar Matrix Effect */
    [data-testid="stSidebar"] {{
        background: rgba(0, 10, 15, 0.95) !important;
        border-right: 1px solid #00f2ff55;
    }}

    /* Custom Scrollbar */
    ::-webkit-scrollbar {{ width: 5px; }}
    ::-webkit-scrollbar-thumb {{ background: #00f2ff; border-radius: 10px; }}
    </style>
    """, unsafe_allow_html=True)

# --- 4. LÃ•I Xá»¬ LÃ AI & QUáº¢N LÃ LUá»’NG (ROUTING) ---
def log_sys(msg):
    ts = datetime.now().strftime("%H:%M:%S")
    st.session_state.terminal_logs.append(f"> [{ts}] {msg}")

def auto_generate_name(history):
    """AI tá»± Ä‘á»™ng Ä‘áº·t tÃªn cuá»™c há»™i thoáº¡i dá»±a trÃªn bá»‘i cáº£nh"""
    if len(history) == 2: # Sau cÃ¢u há»i vÃ  tráº£ lá»i Ä‘áº§u tiÃªn
        try:
            client = OpenAI(api_key=GROQ_KEYS[0], base_url="https://api.groq.com/openai/v1")
            prompt = f"Äáº·t 1 tiÃªu Ä‘á» ngáº¯n gá»n (dÆ°á»›i 5 tá»«) cho ná»™i dung nÃ y: {history[0]['content']}"
            res = client.chat.completions.create(
                model="llama3-8b-8192",
                messages=[{"role": "user", "content": prompt}]
            )
            st.session_state.session_name = res.choices[0].message.content.replace('"', '')
            log_sys(f"Session renamed to: {st.session_state.session_name}")
        except: pass

def get_neural_response(user_input, model_selection):
    # ÄÃ“NG GÃ“I TOÃ€N Bá»˜ LUá»’NG Há»˜I THOáº I (TrÃ­ nhá»› vÄ©nh cá»­u)
    messages = [{"role": m["role"], "content": m["content"]} for m in st.session_state.chat_log]
    messages.append({"role": "user", "content": user_input})
    
    # 1. CHIáº¾N THUáº¬T QUÃ‰T GROQ (1->2->3->4)
    key_pool = list(GROQ_KEYS)
    if "Groq" in model_selection:
        target_idx = int(model_selection.split(" ")[-1]) - 1
        key_pool.insert(0, key_pool.pop(target_idx)) # Æ¯u tiÃªn key Ä‘Æ°á»£c chá»n

    for i, key in enumerate(key_pool):
        try:
            log_sys(f"Äang gá»i Neural Node: Groq-{i+1}...")
            client = OpenAI(api_key=key, base_url="https://api.groq.com/openai/v1")
            return client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=messages, # Gá»­i toÃ n bá»™ context
                stream=True
            ), f"Groq Node {i+1}"
        except:
            log_sys(f"Node-{i+1} quÃ¡ táº£i, Ä‘ang nháº£y táº§ng...")
            continue

    # 2. Dá»° PHÃ’NG GEMINI
    try:
        log_sys("KÃ­ch hoáº¡t vá»‡ tinh dá»± phÃ²ng Gemini...")
        genai.configure(api_key=GEMINI_KEY)
        model = genai.GenerativeModel('gemini-1.5-flash')
        # Chuyá»ƒn Ä‘á»•i context cho Gemini
        gem_hist = [{"role": "user" if m["role"] == "user" else "model", "parts": [m["content"]]} for m in messages[:-1]]
        chat = model.start_chat(history=gem_hist)
        return chat.send_message(user_input, stream=True), "Gemini Ultra"
    except Exception as e:
        log_sys(f"Lá»—i nghiÃªm trá»ng: {str(e)}")
        return None, None

# --- 5. Há»† THá»NG LÆ¯U TRá»® VÃ€ QUáº¢N LÃ PHIÃŠN ---
def save_chat_to_server():
    """Ghi dá»¯ liá»‡u vÃ o session_state (MÃ´ phá»ng server trÃªn Cloud)"""
    session_id = st.session_state.current_session_id
    st.session_state.chat_sessions[session_id] = {
        "name": st.session_state.session_name,
        "log": st.session_state.chat_log,
        "time": datetime.now().strftime("%Y-%m-%d %H:%M")
    }
    # Gá»£i Ã½: Äá»ƒ lÆ°u vÄ©nh viá»…n trÃªn mÃ¡y chá»§ tháº­t, báº¡n cÃ³ thá»ƒ dÃ¹ng requests gá»­i Ä‘áº¿n má»™t Webhook/DB á»Ÿ Ä‘Ã¢y.
    log_sys("Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c Ä‘á»“ng bá»™ vÃ o Database.")

# --- 6. GIAO DIá»†N ÄIá»€U KHIá»‚N CHÃNH (OMNI DASHBOARD) ---
def main():
    # SIDEBAR: CÆ  QUAN LÆ¯U TRá»®
    with st.sidebar:
        st.title("ğŸ’  NEXUS ARCHIVE")
        st.write(f"ğŸ“¡ Status: **Active**")
        
        st.divider()
        st.subheader("ğŸ“ Danh sÃ¡ch há»™i thoáº¡i")
        # Quáº£n lÃ½ phiÃªn lÃ m viá»‡c
        if st.button("+ Táº¡o há»™i thoáº¡i má»›i"):
            st.session_state.current_session_id = f"Node_{random.randint(100,999)}"
            st.session_state.chat_log = []
            st.session_state.session_name = "Cuá»™c há»™i thoáº¡i má»›i"
            st.rerun()

        for sid, data in st.session_state.chat_sessions.items():
            if st.sidebar.button(f"ğŸ“„ {data['name']}", key=sid):
                st.session_state.current_session_id = sid
                st.session_state.chat_log = data['log']
                st.session_state.session_name = data['name']
                st.rerun()

        st.divider()
        # Monitor
        st.write("ğŸ“Š TÃ i nguyÃªn Node")
        st.caption(f"CPU: {psutil.cpu_percent()}% | RAM: {psutil.virtual_memory().percent}%")
        
        # Chá»n Bot
        st.session_state.target_ai = st.selectbox("ğŸ¯ AI Target:", ["Auto-Route", "Groq 1", "Groq 2", "Groq 3", "Gemini"])

    # MÃ€N HÃŒNH CHÃNH
    st.title(f"ğŸš€ {st.session_state.session_name}")
    st.caption(f"ID PhiÃªn: `{st.session_state.current_session_id}` | TrÃ­ nhá»›: `{len(st.session_state.chat_log)} nodes`")

    tab_chat, tab_log, tab_raw = st.tabs(["ğŸ’¬ Giao diá»‡n Neural", "ğŸ“œ Nháº­t kÃ½ Kernel", "ğŸ’¾ Dá»¯ liá»‡u thÃ´"])

    with tab_chat:
        # Hiá»ƒn thá»‹ lá»‹ch sá»­
        for msg in st.session_state.chat_log:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])

        # Input Ä‘iá»u khiá»ƒn
        if prompt := st.chat_input("GÃµ lá»‡nh Ä‘iá»u khiá»ƒn Nexus..."):
            st.session_state.chat_log.append({"role": "user", "content": prompt})
            with st.chat_message("user"): st.markdown(prompt)

            with st.chat_message("assistant"):
                res, source = get_neural_response(prompt, st.session_state.target_ai)
                if res:
                    full_res = ""
                    placeholder = st.empty()
                    for chunk in res:
                        content = chunk.choices[0].delta.content if "Groq" in source else chunk.text
                        if content:
                            full_res += content
                            placeholder.markdown(full_res + "â–ˆ")
                    placeholder.markdown(full_res)
                    st.session_state.chat_log.append({"role": "assistant", "content": full_res})
                    
                    # Tá»± Ä‘á»™ng hÃ³a sau khi pháº£n há»“i
                    auto_generate_name(st.session_state.chat_log)
                    save_chat_to_server()
                    st.rerun()

    with tab_log:
        st.code("\n".join(st.session_state.terminal_logs[::-1]), language="bash")

    with tab_raw:
        st.subheader("ğŸ“¦ Xuáº¥t dá»¯ liá»‡u há»™i thoáº¡i")
        json_data = json.dumps(st.session_state.chat_log, indent=2, ensure_ascii=False)
        st.download_button("Táº£i xuá»‘ng JSON lá»‹ch sá»­", json_data, file_name=f"{st.session_state.session_name}.json")
        st.json(st.session_state.chat_log)

if __name__ == "__main__":
    main()
