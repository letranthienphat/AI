import streamlit as st
from openai import OpenAI
import google.generativeai as genai
import random
import requests
import io
from PIL import Image

# --- 1. C·∫•u h√¨nh h·ªá th·ªëng & Tr√≠ nh·ªõ ---
st.set_page_config(page_title="Nexus OS V55.2", layout="wide")

# Kh·ªüi t·∫°o b·ªô nh·ªõ t√≥m t·∫Øt n·∫øu ch∆∞a c√≥
if 'chat_log' not in st.session_state: st.session_state.chat_log = []
if 'summary' not in st.session_state: st.session_state.summary = ""
if 'bg' not in st.session_state: st.session_state.bg = "https://images.unsplash.com/photo-1451187580459-43490279c0fa?q=80&w=2072"

# --- 2. Giao di·ªán T∆∞∆°ng ph·∫£n cao ---
st.markdown(f"""
    <style>
    .stApp {{
        background: linear-gradient(rgba(0,0,0,0.65), rgba(0,0,0,0.65)), url("{st.session_state.bg}");
        background-size: cover; background-attachment: fixed;
    }}
    .stChatMessage {{
        background: rgba(20, 25, 35, 0.9) !important; /* ƒê·ªô ƒë·∫≠m cao ƒë·ªÉ r√µ ch·ªØ */
        border: 1px solid #00d2ff;
        border-radius: 15px !important;
        color: white !important;
        margin-bottom: 10px;
    }}
    /* N√∫t g·ª£i √Ω x·ªãn */
    .stButton button {{
        background: rgba(0, 210, 255, 0.1);
        border: 1px solid #00d2ff;
        color: #00d2ff;
        border-radius: 20px;
        transition: 0.3s;
    }}
    .stButton button:hover {{
        background: #00d2ff;
        color: black;
    }}
    h1, h2, h3, p, b {{
        color: #ffffff !important;
        text-shadow: 2px 2px 4px rgba(0,0,0,1);
    }}
    </style>
    """, unsafe_allow_html=True)

# --- 3. L√µi x·ª≠ l√Ω AI (T√≥m t·∫Øt & Ph·∫£n h·ªìi) ---
def get_ai_response(prompt, context_summary=""):
    """G·ª≠i k√®m t√≥m t·∫Øt ƒë·ªÉ AI lu√¥n nh·ªõ m√¨nh ƒëang n√≥i v·ªÅ g√¨"""
    full_prompt = f"B·ªëi c·∫£nh tr∆∞·ªõc ƒë√≥: {context_summary}\n\nNg∆∞·ªùi d√πng: {prompt}"
    
    keys = list(st.secrets["GROQ_KEYS"])
    random.shuffle(keys)
    for key in keys:
        try:
            client = OpenAI(api_key=key, base_url="https://api.groq.com/openai/v1")
            return client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": "user", "content": full_prompt}],
                stream=True
            ), "Groq"
        except: continue
    
    genai.configure(api_key=st.secrets["GEMINI_KEY"])
    return genai.GenerativeModel('gemini-1.5-flash').generate_content(full_prompt, stream=True), "Gemini"

def update_summary():
    """T·ª± ƒë·ªông t√≥m t·∫Øt khi chat ƒë·∫°t tr√™n 5 c√¢u ƒë·ªÉ ti·∫øt ki·ªám b·ªô nh·ªõ"""
    if len(st.session_state.chat_log) > 5:
        history = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.chat_log[-4:]])
        summary_prompt = f"H√£y t√≥m t·∫Øt ng·∫Øn g·ªçn cu·ªôc tr√≤ chuy·ªán n√†y trong 2 c√¢u ƒë·ªÉ t√¥i ghi nh·ªõ: {history}"
        # G·ªçi Gemini ƒë·ªÉ t√≥m t·∫Øt nhanh
        genai.configure(api_key=st.secrets["GEMINI_KEY"])
        res = genai.GenerativeModel('gemini-1.5-flash').generate_content(summary_prompt)
        st.session_state.summary = res.text

# --- 4. Giao di·ªán ch√≠nh ---
def main():
    with st.sidebar:
        st.title("üí† NEXUS OS V55.2")
        st.write(f"üß† Tr√≠ nh·ªõ hi·ªán t·∫°i: {st.session_state.summary[:50]}...")
        if st.button("üóëÔ∏è X√≥a tr√≠ nh·ªõ"):
            st.session_state.chat_log = []
            st.session_state.summary = ""
            st.rerun()
        st.divider()
        st.session_state.bg = st.text_input("ƒê·ªïi h√¨nh n·ªÅn:", st.session_state.bg)

    st.title("ü§ñ Neural Terminal")

    # Hi·ªÉn th·ªã Chat
    for msg in st.session_state.chat_log:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # N√∫t g·ª£i √Ω ch·ªß ƒë·ªông
    if st.session_state.chat_log:
        cols = st.columns(3)
        suggestions = ["Gi·∫£i th√≠ch r√µ h∆°n", "V√≠ d·ª• c·ª• th·ªÉ", "Vi·∫øt code t√≠nh nƒÉng n√†y"]
        for i, sug in enumerate(suggestions):
            if cols[i].button(f"üí° {sug}"):
                process_chat(sug)

    # Input ng∆∞·ªùi d√πng
    if p := st.chat_input("H·ªèi Nexus b·∫•t c·ª© ƒëi·ªÅu g√¨..."):
        process_chat(p)

def process_chat(user_input):
    st.session_state.chat_log.append({"role": "user", "content": user_input})
    
    with st.chat_message("assistant"):
        res, provider = get_ai_response(user_input, st.session_state.summary)
        box = st.empty(); full = ""
        if res:
            for chunk in res:
                content = chunk.choices[0].delta.content if provider == "Groq" else chunk.text
                if content:
                    full += content
                    box.markdown(full + "‚ñå")
            box.markdown(full)
            st.session_state.chat_log.append({"role": "assistant", "content": full})
            update_summary() # C·∫≠p nh·∫≠t tr√≠ nh·ªõ sau m·ªói l·∫ßn chat
            st.rerun()

if __name__ == "__main__":
    main()
