import streamlit as st
from openai import OpenAI
from gtts import gTTS
from io import BytesIO
from streamlit_mic_recorder import mic_recorder
import qrcode
import base64
from langdetect import detect

# --- 1. Cáº¤U HÃŒNH UI GRID POWER (NÃšT TÃCH BIá»†T) ---
st.set_page_config(page_title="Nexus Grid Power", layout="wide", page_icon="âš¡")

st.markdown("""
    <style>
    /* Ná»n tráº¯ng sang trá»ng */
    .stApp { background-color: #ffffff; }
    
    /* Hiá»‡u á»©ng nÃºt gá»£i Ã½ tÃ¡ch biá»‡t hoÃ n toÃ n */
    .suggestion-container {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
        gap: 12px;
        margin: 15px 0;
    }
    
    /* Ã‰p cÃ¡c nÃºt Streamlit trong khu vá»±c gá»£i Ã½ pháº£i trÃ´ng Ä‘áº¹p hÆ¡n */
    div.stButton > button {
        width: 100%;
        border-radius: 12px !important;
        border: 1px solid #007bff !important;
        background-color: #f0f7ff !important;
        color: #007bff !important;
        font-weight: 500;
        transition: all 0.2s ease-in-out;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    
    div.stButton > button:hover {
        background-color: #007bff !important;
        color: white !important;
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
    }

    /* Action bar cho tá»«ng tin nháº¯n */
    .action-row { display: flex; gap: 8px; flex-wrap: wrap; margin-top: 10px; }

    /* Input cá»‘ Ä‘á»‹nh Ä‘Ã¡y */
    .stChatInputContainer { position: fixed; bottom: 0; background: white; z-index: 1000; padding: 10px 0; }
    </style>
    """, unsafe_allow_html=True)

# --- 2. HÃ€M Há»– TRá»¢ NGÃ”N NGá»® & VOICE ---
def speak_js(text, speed, lang):
    clean = text.replace('"', "'").replace('\n', ' ')
    return f"<script>window.speechSynthesis.cancel(); var m=new SpeechSynthesisUtterance('{clean}'); m.lang='{lang}'; m.rate={speed}; window.speechSynthesis.speak(m);</script>"

def get_lang_code(text):
    try:
        l = detect(text)
        mapping = {"vi":"vi-VN", "en":"en-US", "ja":"ja-JP", "ko":"ko-KR", "fr":"fr-FR"}
        return mapping.get(l, "vi-VN")
    except: return "vi-VN"

# --- 3. KHá»I Táº O STATE ---
if "messages" not in st.session_state: st.session_state.messages = []
if "suggestions" not in st.session_state: st.session_state.suggestions = ["ChÃ o báº¡n!", "Báº¡n khá»e khÃ´ng?", "Dá»‹ch tin nháº¯n", "Ká»ƒ chuyá»‡n cÆ°á»i"]
if "voice_draft" not in st.session_state: st.session_state.voice_draft = ""

client = OpenAI(api_key=st.secrets["GROQ_API_KEY"], base_url="https://api.groq.com/openai/v1")

# --- 4. HÃ€M Xá»¬ LÃ CHÃNH ---
def process_ai(user_input):
    st.session_state.messages.append({"role": "user", "content": user_input})
    lang = get_lang_code(user_input)
    
    with st.chat_message("assistant"):
        p = st.empty(); full = ""
        res = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages],
            stream=True
        )
        for chunk in res:
            if chunk.choices[0].delta.content:
                full += chunk.choices[0].delta.content
                p.markdown(full + "â–Œ")
        p.markdown(full)
        st.session_state.messages.append({"role": "assistant", "content": full})
        
        # PhÃ¡t voice tá»± Ä‘á»™ng
        if st.session_state.get("auto_read", True):
            st.components.v1.html(speak_js(full, st.session_state.v_speed, lang), height=0)

        # Cáº¬P NHáº¬T Gá»¢I Ã Äá»˜NG (DYNAMIC)
        try:
            sug_res = client.chat.completions.create(
                model="llama-3.1-8b-instant",
                messages=[{"role": "user", "content": f"Dá»±a trÃªn: '{full[:150]}', táº¡o 4 cÃ¢u há»i tiáº¿p ná»‘i cá»±c ngáº¯n (2-4 tá»«). NgÃ´n ngá»¯: {lang}. Tráº£ vá» dáº¡ng: cÃ¢u 1, cÃ¢u 2, cÃ¢u 3, cÃ¢u 4"}]
            )
            st.session_state.suggestions = sug_res.choices[0].message.content.split(',')
        except: pass

# --- 5. SIDEBAR ---
with st.sidebar:
    st.title("âš™ï¸ Äiá»u khiá»ƒn")
    st.session_state.v_speed = st.slider("Tá»‘c Ä‘á»™ Ä‘á»c", 0.5, 2.0, 1.1)
    if st.button("ğŸ›‘ Dá»ªNG Äá»ŒC", type="primary", use_container_width=True):
        st.components.v1.html("<script>window.speechSynthesis.cancel();</script>", height=0)
    st.session_state.auto_read = st.toggle("Tá»± Ä‘á»™ng Ä‘á»c", value=True)
    hands_free = st.toggle("ğŸ™ï¸ Ráº£nh tay", value=False)
    
    if st.button("ğŸ—‘ï¸ XÃ³a há»™i thoáº¡i", use_container_width=True):
        st.session_state.messages = []; st.rerun()

# --- 6. GIAO DIá»†N CHÃNH ---
st.title("Nexus Grid Power âš¡")

# Hiá»ƒn thá»‹ há»™i thoáº¡i
for i, m in enumerate(st.session_state.messages):
    with st.chat_message(m["role"]):
        st.markdown(m["content"])
        if m["role"] == "assistant":
            # Action Bar (NÃºt chá»©c nÄƒng dÆ°á»›i tin nháº¯n)
            c1, c2, c3 = st.columns([1, 1, 1])
            with c1:
                if st.button("ğŸ”Š Nghe láº¡i", key=f"r_{i}"):
                    st.components.v1.html(speak_js(m["content"], st.session_state.v_speed, get_lang_code(m["content"])), height=0)
            with c2:
                # NÃºt táº£i mp3
                try:
                    tts = gTTS(text=m["content"][:250], lang=get_lang_code(m["content"]).split('-')[0])
                    b = BytesIO(); tts.write_to_fp(b); b64 = base64.b64encode(b.getvalue()).decode()
                    st.markdown(f'<a href="data:audio/mp3;base64,{b64}" download="voice.mp3"><button style="width:100%; border-radius:12px; border:1px solid #ddd; padding:6px; cursor:pointer;">ğŸ“¥ Táº£i vá»</button></a>', unsafe_allow_html=True)
                except: pass
            with c3:
                if st.button("ğŸ“‹ Copy", key=f"cp_{i}"):
                    st.toast("ÄÃ£ sao chÃ©p!")

# KHU Vá»°C Gá»¢I Ã (NÃºt báº¥m tÃ¡ch biá»‡t hoÃ n toÃ n)
st.write("---")
st.caption("ğŸ” Gá»£i Ã½ thÃ´ng minh cho báº¡n:")
# Sá»­ dá»¥ng container Ä‘á»ƒ bao bá»c cÃ¡c nÃºt gá»£i Ã½ tÃ¡ch biá»‡t
with st.container():
    # Chia thÃ nh cÃ¡c cá»™t nhá» Ä‘á»ƒ táº¡o hiá»‡u á»©ng tÃ¡ch biá»‡t tá»«ng nÃºt
    sug_cols = st.columns(len(st.session_state.suggestions))
    for idx, sug in enumerate(st.session_state.suggestions):
        clean_sug = sug.strip().replace('"', '')
        if sug_cols[idx].button(clean_sug, key=f"sug_{idx}_{hash(clean_sug)}", use_container_width=True):
            process_ai(clean_sug)
            st.rerun()

# --- 7. INPUT (MIC & TEXT) ---
st.write("<br><br><br><br>", unsafe_allow_html=True)

if st.session_state.voice_draft and not hands_free:
    with st.container():
        st.warning("ğŸ™ï¸ Sá»­a báº£n dá»‹ch:")
        txt = st.text_area("", value=st.session_state.voice_draft, height=70)
        c_ok, c_no = st.columns(2)
        if c_ok.button("ğŸš€ Gá»¬I"):
            st.session_state.voice_draft = ""; process_ai(txt); st.rerun()
        if c_no.button("ğŸ—‘ï¸ Há»¦Y"):
            st.session_state.voice_draft = ""; st.rerun()
else:
    c_m, c_i = st.columns([1, 6])
    with c_m:
        audio = mic_recorder(start_prompt="ğŸ¤", stop_prompt="â¹ï¸", key='mic_v11')
    if audio:
        with st.spinner(""):
            transcript = client.audio.transcriptions.create(model="whisper-large-v3-turbo", file=("v.wav", audio['bytes']))
            if hands_free: process_ai(transcript.text); st.rerun()
            else: st.session_state.voice_draft = transcript.text; st.rerun()

    inp = st.chat_input("Há»i tÃ´i báº¥t cá»© Ä‘iá»u gÃ¬...")
    if inp: process_ai(inp); st.rerun()
