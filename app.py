import streamlit as st
from openai import OpenAI
from gtts import gTTS
from io import BytesIO
from streamlit_mic_recorder import mic_recorder
import time

# --- C·∫§U H√åNH H·ªÜ TH·ªêNG ---
st.set_page_config(page_title="AI Voice Commander", layout="wide", page_icon="üî•")

# CSS: T·ªëi ∆∞u h√≥a kho·∫£ng c√°ch, l√†m ƒë·∫πp n√∫t b·∫•m v√† c·ªë ƒë·ªãnh khung chat
st.markdown("""
    <style>
    .stTextArea textarea { font-size: 16px; background-color: #f0f2f6; border-radius: 10px; }
    .stButton button { border-radius: 20px; font-weight: bold; }
    div[data-testid="stChatMessageContent"] { background-color: #ffffff; border-radius: 15px; padding: 10px; border: 1px solid #e0e0e0; }
    .draft-box { border: 2px solid #4CAF50; padding: 15px; border-radius: 15px; background-color: #e8f5e9; margin-bottom: 20px; }
    </style>
    """, unsafe_allow_html=True)

# API SETUP
GROQ_API_KEY = st.secrets.get("GROQ_API_KEY", "")
client = OpenAI(api_key=GROQ_API_KEY, base_url="https://api.groq.com/openai/v1")

# --- QU·∫¢N L√ù TR·∫†NG TH√ÅI (SESSION STATE) ---
if "messages" not in st.session_state: st.session_state.messages = []
if "voice_draft" not in st.session_state: st.session_state.voice_draft = None # L∆∞u b·∫£n nh√°p gi·ªçng n√≥i
if "last_read_index" not in st.session_state: st.session_state.last_read_index = -1 # ƒê·ªÉ kh√¥ng ƒë·ªçc l·∫°i tin c≈©
if "processing" not in st.session_state: st.session_state.processing = False

# --- H√ÄM X·ª¨ L√ù ---
def text_to_speech(text, speed=1.0):
    try:
        tts = gTTS(text=text, lang='vi')
        fp = BytesIO()
        tts.write_to_fp(fp)
        return fp.getvalue()
    except: return None

def process_ai_response():
    """G·ª≠i tin nh·∫Øn ƒë·∫øn AI v√† nh·∫≠n ph·∫£n h·ªìi stream"""
    st.session_state.processing = True
    full_res = ""
    res_area = st.empty()
    
    try:
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages],
            stream=True
        )
        for chunk in response:
            if chunk.choices[0].delta.content:
                full_res += chunk.choices[0].delta.content
                res_area.markdown(full_res + "‚ñå")
        
        res_area.markdown(full_res)
        st.session_state.messages.append({"role": "assistant", "content": full_res})
    except Exception as e:
        st.error(f"L·ªói AI: {e}")
    finally:
        st.session_state.processing = False
        st.rerun()

# --- SIDEBAR ---
with st.sidebar:
    st.header("üéõÔ∏è B·∫£ng ƒêi·ªÅu Khi·ªÉn")
    speed = st.slider("T·ªëc ƒë·ªô ƒë·ªçc", 0.5, 2.0, 1.0, 0.1)
    auto_read = st.toggle("T·ª± ƒë·ªông ƒë·ªçc tin m·ªõi", value=True)
    
    st.divider()
    if st.button("üóëÔ∏è X√≥a L·ªãch S·ª≠ Chat"):
        st.session_state.messages = []
        st.session_state.voice_draft = None
        st.session_state.last_read_index = -1
        st.rerun()

# --- GIAO DI·ªÜN CH√çNH ---
st.title("üî• AI Voice Commander")

# 1. HI·ªÇN TH·ªä L·ªäCH S·ª¨ CHAT
chat_container = st.container()
with chat_container:
    for i, m in enumerate(st.session_state.messages):
        with st.chat_message(m["role"]):
            st.markdown(m["content"])
            
            # Logic ƒë·ªçc gi·ªçng n√≥i th√¥ng minh: Ch·ªâ ƒë·ªçc tin nh·∫Øn M·ªöI NH·∫§T c·ªßa AI
            if m["role"] == "assistant":
                # N√∫t ƒë·ªçc th·ªß c√¥ng lu√¥n hi·ªán
                if st.button("üîä", key=f"read_{i}"):
                    audio = text_to_speech(m["content"], speed)
                    st.audio(audio, format="audio/mp3", autoplay=True)
                
                # T·ª± ƒë·ªông ƒë·ªçc (Ch·ªâ ƒë·ªçc 1 l·∫ßn khi tin nh·∫Øn v·ª´a xu·∫•t hi·ªán)
                if auto_read and i > st.session_state.last_read_index:
                    st.session_state.last_read_index = i # C·∫≠p nh·∫≠t ƒë√£ ƒë·ªçc tin n√†y r·ªìi
                    audio = text_to_speech(m["content"], speed)
                    if audio:
                        st.audio(audio, format="audio/mp3", autoplay=True)

# 2. KHU V·ª∞C T∆Ø∆†NG T√ÅC (ƒê·ªòT PH√Å ·ªû ƒê√ÇY)
st.divider()

# N·∫øu ƒëang c√≥ b·∫£n nh√°p gi·ªçng n√≥i -> Hi·ªán giao di·ªán CH·ªàNH S·ª¨A ƒê·∫∂C BI·ªÜT
if st.session_state.voice_draft is not None:
    st.markdown('<div class="draft-box">üéôÔ∏è <b>Ch·∫ø ƒë·ªô ch·ªânh s·ª≠a gi·ªçng n√≥i</b></div>', unsafe_allow_html=True)
    
    # Text Area ƒëi·ªÅn s·∫µn n·ªôi dung t·ª´ Mic
    edited_text = st.text_area("N·ªôi dung ƒë√£ nghe ƒë∆∞·ª£c (S·ª≠a l·∫°i n·∫øu c·∫ßn):", 
                               value=st.session_state.voice_draft, 
                               height=100,
                               key="draft_editor")
    
    col_confirm, col_cancel = st.columns([1, 1])
    with col_confirm:
        if st.button("üöÄ G·ª¨I NGAY (Enter)", type="primary", use_container_width=True):
            if edited_text.strip():
                st.session_state.messages.append({"role": "user", "content": edited_text})
                st.session_state.voice_draft = None # X√≥a nh√°p
                process_ai_response()
    
    with col_cancel:
        if st.button("‚ùå H·ªßy b·ªè", use_container_width=True):
            st.session_state.voice_draft = None
            st.rerun()

# N·∫øu KH√îNG c√≥ b·∫£n nh√°p -> Hi·ªán giao di·ªán NH·∫¨P LI·ªÜU CHU·∫®N (Mic + Chat Input)
else:
    c1, c2 = st.columns([1, 8])
    
    with c1:
        # N√∫t Mic
        audio_data = mic_recorder(start_prompt="üé§", stop_prompt="‚èπÔ∏è", key='mic_main')
    
    with c2:
        # Chat Input th∆∞·ªùng
        user_input = st.chat_input("G√µ tin nh·∫Øn ho·∫∑c nh·∫•n Mic b√™n tr√°i...")

    # LOGIC X·ª¨ L√ù INPUT
    
    # Tr∆∞·ªùng h·ª£p A: C√≥ Audio m·ªõi
    if audio_data:
        with st.spinner("‚ö° ƒêang ph√¢n t√≠ch gi·ªçng n√≥i..."):
            with open("voice_temp.wav", "wb") as f:
                f.write(audio_data['bytes'])
            with open("voice_temp.wav", "rb") as af:
                transcript = client.audio.transcriptions.create(
                    model="whisper-large-v3-turbo", file=af, language="vi"
                )
            # L∆ØU V√ÄO DRAFT V√Ä RELOAD ƒê·ªÇ HI·ªÜN KHUNG S·ª¨A
            st.session_state.voice_draft = transcript.text
            st.rerun()

    # Tr∆∞·ªùng h·ª£p B: Ng∆∞·ªùi d√πng g√µ ph√≠m Enter
    if user_input:
        st.session_state.messages.append({"role": "user", "content": user_input})
        process_ai_response()
