import streamlit as st
from openai import OpenAI
from gtts import gTTS
from io import BytesIO
from streamlit_mic_recorder import mic_recorder
import qrcode
import base64
from langdetect import detect
import re

# --- 1. Cáº¤U HÃŒNH GIAO DIá»†N SIÃŠU Cáº¤P (RESPONSIVE) ---
st.set_page_config(page_title="AI Nexus v13 Full", layout="wide", page_icon="ğŸ’")

st.markdown("""
    <style>
    .stApp { background-color: #ffffff; }
    
    /* Bong bÃ³ng chat tinh táº¿ */
    div[data-testid="stChatMessage"] {
        border-radius: 15px; margin-bottom: 12px;
        border: 1px solid #f0f0f0; box-shadow: 0 4px 12px rgba(0,0,0,0.03);
    }

    /* Action Bar dÆ°á»›i má»—i tin nháº¯n */
    .action-row { display: flex; gap: 10px; flex-wrap: wrap; margin-top: 10px; }
    
    /* Thiáº¿t káº¿ nÃºt Gá»£i Ã½ (Atomic Buttons) */
    .stButton > button {
        border-radius: 20px !important;
        border: 1px solid #007bff !important;
        background-color: #f8fbff !important;
        color: #007bff !important;
        font-weight: 600 !important;
        transition: 0.3s;
    }
    .stButton > button:hover {
        background-color: #007bff !important;
        color: white !important;
    }

    /* Cá»‘ Ä‘á»‹nh Input Bar Ä‘Ã¡y mÃ n hÃ¬nh */
    .stChatInputContainer { position: fixed; bottom: 0; background: white; z-index: 1000; padding: 10px 0; }
    </style>
    """, unsafe_allow_html=True)

# --- 2. HÃ€M TRá»¢ NÄ‚NG (VOICE, LANG, COPY) ---
def speak_js(text, speed, lang):
    clean = text.replace('"', "'").replace('\n', ' ')
    return f"<script>window.speechSynthesis.cancel(); var m=new SpeechSynthesisUtterance('{clean}'); m.lang='{lang}'; m.rate={speed}; window.speechSynthesis.speak(m);</script>"

def get_lang_code(text):
    try:
        l = detect(text)
        mapping = {"vi":"vi-VN", "en":"en-US", "ja":"ja-JP", "ko":"ko-KR", "fr":"fr-FR"}
        return mapping.get(l, "vi-VN")
    except: return "vi-VN"

# --- 3. KHá»I Táº O STATE ---
if "messages" not in st.session_state: st.session_state.messages = []
if "suggestions" not in st.session_state: st.session_state.suggestions = ["ChÃ o báº¡n", "HÃ´m nay cÃ³ gÃ¬ má»›i?", "Ká»ƒ chuyá»‡n cÆ°á»i", "Dá»‹ch tiáº¿ng Anh"]
if "voice_draft" not in st.session_state: st.session_state.voice_draft = ""

client = OpenAI(api_key=st.secrets["GROQ_API_KEY"], base_url="https://api.groq.com/openai/v1")

# --- 4. HÃ€M Xá»¬ LÃ AI & Gá»¢I Ã TÃCH BIá»†T ---
def process_ai(user_input):
    st.session_state.messages.append({"role": "user", "content": user_input})
    lang = get_lang_code(user_input)
    
    with st.chat_message("assistant"):
        p = st.empty(); full = ""
        res = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages],
            stream=True
        )
        for chunk in res:
            if chunk.choices[0].delta.content:
                full += chunk.choices[0].delta.content
                p.markdown(full + "â–Œ")
        p.markdown(full)
        st.session_state.messages.append({"role": "assistant", "content": full})
        
        # Tá»± Ä‘á»™ng Ä‘á»c
        if st.session_state.get("auto_read", True):
            st.components.v1.html(speak_js(full, st.session_state.get("v_speed", 1.1), lang), height=0)

        # Cáº­p nháº­t gá»£i Ã½: TÃ¡ch biá»‡t tá»«ng Ã½ thÃ nh tá»«ng pháº§n tá»­ máº£ng
        try:
            sug_res = client.chat.completions.create(
                model="llama-3.1-8b-instant",
                messages=[{"role": "user", "content": f"Dá»±a trÃªn cÃ¢u tráº£ lá»i: '{full[:150]}', táº¡o 4 cÃ¢u há»i tiáº¿p ná»‘i cá»±c ngáº¯n. Tráº£ vá» cÃ¡c cÃ¢u cÃ¡ch nhau báº±ng dáº¥u pháº©y, khÃ´ng Ä‘Ã¡nh sá»‘."}]
            )
            raw = sug_res.choices[0].message.content
            st.session_state.suggestions = [s.strip() for s in re.split(',|\n', raw) if s.strip()][:4]
        except: pass

# --- 5. SIDEBAR: TRUNG TÃ‚M Dá»® LIá»†U & CÃ€I Äáº¶T ---
with st.sidebar:
    st.title("âš™ï¸ Há»‡ thá»‘ng v13")
    st.session_state.v_speed = st.slider("Tá»‘c Ä‘á»™ Ä‘á»c", 0.5, 2.0, 1.1)
    if st.button("ğŸ›‘ Dá»ªNG Äá»ŒC", type="primary", use_container_width=True):
        st.components.v1.html("<script>window.speechSynthesis.cancel();</script>", height=0)
    
    st.divider()
    st.session_state.auto_read = st.toggle("Tá»± Ä‘á»™ng Ä‘á»c", value=True)
    hands_free = st.toggle("ğŸ™ï¸ Ráº£nh tay", value=False)
    
    # TÃNH NÄ‚NG SAO LÆ¯U (BACKUP)
    st.subheader("ğŸ“‚ Sao lÆ°u & Phá»¥c há»“i")
    history_raw = "\n".join([f"{m['role'].upper()}: {m['content']}" for m in st.session_state.messages])
    
    st.download_button("ğŸ“¤ Xuáº¥t file .txt", data=history_raw, file_name="ai_chat_backup.txt", use_container_width=True)
    
    uploaded_file = st.file_uploader("ğŸ“¥ Nháº­p file .txt", type="txt")
    if uploaded_file:
        if st.button("ğŸ”„ KhÃ´i phá»¥c ngay"):
            content = uploaded_file.getvalue().decode("utf-8")
            # Logic khÃ´i phá»¥c Ä‘Æ¡n giáº£n (cÃ³ thá»ƒ nÃ¢ng cáº¥p thÃªm)
            st.info("ÄÃ£ nháº­n dá»¯ liá»‡u, hÃ£y chat Ä‘á»ƒ tiáº¿p tá»¥c!")

    if st.button("ğŸ—‘ï¸ XÃ³a sáº¡ch há»™i thoáº¡i", use_container_width=True):
        st.session_state.messages = []; st.rerun()

# --- 6. GIAO DIá»†N CHÃNH ---
st.title("AI Nexus v13: Legacy ğŸ’")

# Hiá»ƒn thá»‹ há»™i thoáº¡i
for i, m in enumerate(st.session_state.messages):
    with st.chat_message(m["role"]):
        st.markdown(m["content"])
        if m["role"] == "assistant":
            # Action Bar: Äáº§y Ä‘á»§ cÃ¡c nÃºt
            c1, c2, c3 = st.columns([1, 1, 1])
            with c1:
                if st.button("ğŸ”Š Nghe láº¡i", key=f"r_{i}"):
                    st.components.v1.html(speak_js(m["content"], st.session_state.v_speed, get_lang_code(m["content"])), height=0)
            with c2:
                # TÃ­nh nÄƒng Táº£i Ã¢m thanh
                try:
                    tts = gTTS(text=m["content"][:250], lang=get_lang_code(m["content"]).split('-')[0])
                    b = BytesIO(); tts.write_to_fp(b); b64 = base64.b64encode(b.getvalue()).decode()
                    st.markdown(f'<a href="data:audio/mp3;base64,{b64}" download="ai_voice.mp3"><button style="width:100%; border-radius:15px; border:1px solid #ddd; padding:5px; cursor:pointer;">ğŸ“¥ Táº£i Mp3</button></a>', unsafe_allow_html=True)
                except: pass
            with c3:
                # TÃ­nh nÄƒng QR Code cho tá»«ng tin nháº¯n (Náº¿u cáº§n)
                if st.button("ğŸ“± QR", key=f"qr_{i}"):
                    qr = qrcode.make(m["content"][:500]); buf = BytesIO(); qr.save(buf, format="PNG")
                    st.image(buf, width=150)

# --- KHU Vá»°C NÃšT Gá»¢I Ã NGUYÃŠN Tá»¬ (ATOMIC) ---
st.write("---")
st.caption("ğŸ’¡ Gá»£i Ã½ cho báº¡n (Má»—i nÃºt má»™t Ã½):")
if st.session_state.suggestions:
    # Chia cá»™t Ä‘á»ƒ má»—i nÃºt náº±m riÃªng biá»‡t
    cols = st.columns(len(st.session_state.suggestions))
    for idx, sug in enumerate(st.session_state.suggestions):
        # LÃ m sáº¡ch vÄƒn báº£n gá»£i Ã½ (bá» sá»‘ thá»© tá»±, gáº¡ch Ä‘áº§u dÃ²ng)
        clean_sug = re.sub(r'^\d+\.\s*|-\s*', '', sug).strip().replace('"', '')
        if cols[idx].button(clean_sug, key=f"sug_{idx}_{hash(clean_sug)}", use_container_width=True):
            process_ai(clean_sug)
            st.rerun()

# --- 7. KHU Vá»°C NHáº¬P LIá»†U (MOBILE READY) ---
st.write("<br><br><br><br>", unsafe_allow_html=True)

if st.session_state.voice_draft and not hands_free:
    with st.container():
        st.warning("ğŸ™ï¸ Báº£n dá»‹ch giá»ng nÃ³i:")
        txt = st.text_area("", value=st.session_state.voice_draft, height=80)
        ca, cb = st.columns(2)
        if ca.button("ğŸš€ Gá»¬I", use_container_width=True):
            st.session_state.voice_draft = ""; process_ai(txt); st.rerun()
        if cb.button("ğŸ—‘ï¸ Há»¦Y", use_container_width=True):
            st.session_state.voice_draft = ""; st.rerun()
else:
    col_m, col_i = st.columns([1, 6])
    with col_m:
        audio = mic_recorder(start_prompt="ğŸ¤", stop_prompt="â¹ï¸", key='mic_v13')
    if audio:
        with st.spinner(""):
            transcript = client.audio.transcriptions.create(model="whisper-large-v3-turbo", file=("v.wav", audio['bytes']))
            if hands_free: process_ai(transcript.text); st.rerun()
            else: st.session_state.voice_draft = transcript.text; st.rerun()

    inp = st.chat_input("Há»i tÃ´i báº¥t cá»© Ä‘iá»u gÃ¬...")
    if inp: process_ai(inp); st.rerun()
