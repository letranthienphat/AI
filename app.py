import streamlit as st
from openai import OpenAI
from streamlit_mic_recorder import mic_recorder
import qrcode
from io import BytesIO

# --- 1. C·∫§U H√åNH H·ªÜ TH·ªêNG ---
st.set_page_config(page_title="AI Zen Master", layout="wide", page_icon="üßò")

st.markdown("""
    <style>
    .stApp { background-color: #ffffff; color: #333333; }
    .stChatMessage { border-radius: 15px; background: #f7f7f7; border: none; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
    div[data-testid="stToolbar"] { visibility: hidden; }
    .stButton button { border-radius: 20px; font-weight: 600; transition: all 0.2s; }
    .stButton button:hover { transform: scale(1.02); }
    </style>
    """, unsafe_allow_html=True)

# --- 2. H√ÄM ƒê·ªåC GI·ªåNG N√ìI (JS BROWSER TTS) ---
def speak_js(text, speed):
    if not text: return ""
    clean_text = text.replace('"', "'").replace('\n', ' ')
    return f"""
    <script>
    window.speechSynthesis.cancel(); 
    var msg = new SpeechSynthesisUtterance("{clean_text}");
    msg.lang = 'vi-VN';
    msg.rate = {speed};
    window.speechSynthesis.speak(msg);
    </script>
    """

# --- 3. KH·ªûI T·∫†O STATE ---
if "messages" not in st.session_state: st.session_state.messages = []
if "draft_text" not in st.session_state: st.session_state.draft_text = ""

# API Client
try:
    client = OpenAI(api_key=st.secrets["GROQ_API_KEY"], base_url="https://api.groq.com/openai/v1")
except:
    st.error("‚ö†Ô∏è Ch∆∞a c·∫•u h√¨nh GROQ_API_KEY trong Secrets!")
    st.stop()

# --- 4. H√ÄM X·ª¨ L√ù AI TRUNG T√ÇM ---
def process_response(user_input):
    if not user_input: return
    
    # Th√™m tin nh·∫Øn user
    st.session_state.messages.append({"role": "user", "content": user_input})
    
    # G·ªçi AI
    with st.chat_message("assistant"):
        placeholder = st.empty()
        full_res = ""
        try:
            stream = client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages],
                stream=True
            )
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    full_res += chunk.choices[0].delta.content
                    placeholder.markdown(full_res + "‚ñå")
            placeholder.markdown(full_res)
            st.session_state.messages.append({"role": "assistant", "content": full_res})
            
            # ƒê·ªçc ph·∫£n h·ªìi
            if st.session_state.auto_read:
                st.components.v1.html(speak_js(full_res, st.session_state.voice_speed), height=0)
                
        except Exception as e:
            st.error(f"L·ªói: {e}")

# --- 5. SIDEBAR ---
with st.sidebar:
    st.header("üéõÔ∏è B·∫£ng ƒêi·ªÅu Khi·ªÉn")
    st.session_state.voice_speed = st.slider("T·ªëc ƒë·ªô n√≥i", 0.5, 2.0, 1.1)
    st.session_state.auto_read = st.toggle("T·ª± ƒë·ªông ƒë·ªçc", value=True)
    
    st.divider()
    st.subheader("üöÄ Ch·∫ø ƒë·ªô Nh·∫≠p li·ªáu")
    # T√çNH NƒÇNG ƒê·ªòT PH√Å: G·ª¨I NGAY KH√îNG C·∫¶N H·ªéI
    hands_free = st.toggle("‚ö° Ch·∫ø ƒë·ªô R·∫£nh tay (G·ª≠i lu√¥n)", value=False, help="B·∫≠t c√°i n√†y l√™n th√¨ n√≥i xong g·ª≠i lu√¥n, kh√¥ng h·ªèi l·∫°i n·ªØa.")
    
    st.divider()
    if st.button("üóëÔ∏è X√≥a L·ªãch S·ª≠"):
        st.session_state.messages = []
        st.session_state.draft_text = ""
        st.rerun()

# --- 6. GIAO DI·ªÜN CH√çNH ---
st.title("AI Zen Master üßò")

# Hi·ªÉn th·ªã chat
for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# --- 7. INPUT AREA (LOGIC M·ªöI) ---
st.write("---")

# Logic Draft: N·∫øu c√≥ b·∫£n nh√°p th√¨ hi·ªán khung s·ª≠a, mic t·∫°m ·∫©n ƒë·ªÉ tr√°nh xung ƒë·ªôt
if st.session_state.draft_text and not hands_free:
    with st.container():
        st.info("üìù **B·∫£n nh√°p gi·ªçng n√≥i** (S·ª≠a r·ªìi nh·∫•n G·ª≠i)")
        edited_text = st.text_area("N·ªôi dung:", value=st.session_state.draft_text, height=100, key="editor")
        
        c1, c2 = st.columns([1, 1])
        if c1.button("üöÄ G·ª¨I ƒêI", type="primary", use_container_width=True):
            st.session_state.draft_text = "" # X√≥a nh√°p TR∆Ø·ªöC khi g·ª≠i
            process_response(edited_text)
            st.rerun()
            
        if c2.button("‚ùå H·ª¶Y B·ªé", use_container_width=True):
            st.session_state.draft_text = "" # X√≥a nh√°p
            st.rerun()

else:
    # N·∫øu kh√¥ng c√≥ nh√°p th√¨ hi·ªán Mic v√† Chat Input
    c_mic, c_input = st.columns([1, 10])
    
    with c_mic:
        # Mic Recorder
        audio_data = mic_recorder(start_prompt="üé§", stop_prompt="‚èπÔ∏è", key='mic_zen')
    
    # X·ª≠ l√Ω ngay khi c√≥ Audio
    if audio_data:
        # D√πng Whisper Turbo
        with st.spinner("‚ö°"):
            transcript = client.audio.transcriptions.create(
                model="whisper-large-v3-turbo", 
                file=("voice.wav", audio_data['bytes']),
                language="vi"
            )
            text_result = transcript.text
            
            if hands_free:
                # N·∫øu b·∫≠t R·∫£nh tay -> G·ª≠i lu√¥n
                process_response(text_result)
                st.rerun()
            else:
                # N·∫øu t·∫Øt R·∫£nh tay -> L∆∞u v√†o nh√°p ƒë·ªÉ hi·ªán khung s·ª≠a
                st.session_state.draft_text = text_result
                st.rerun()

    # Chat Input th∆∞·ªùng
    text_input = st.chat_input("Nh·∫≠p tin nh·∫Øn...")
    if text_input:
        process_response(text_input)
        st.rerun()
