import streamlit as st
from openai import OpenAI
from gtts import gTTS
from io import BytesIO
from streamlit_mic_recorder import mic_recorder
import qrcode
import base64
from langdetect import detect, detect_langs

# --- 1. Cáº¤U HÃŒNH UI SIÃŠU Cáº¤P (RESPONSIVE) ---
st.set_page_config(page_title="AI Nexus Omni", layout="wide", page_icon="âš¡")

st.markdown("""
    <style>
    /* Mobile-first: Tá»‘i Æ°u khoáº£ng cÃ¡ch vÃ  kÃ­ch thÆ°á»›c nÃºt */
    .stApp { transition: all 0.3s; }
    div[data-testid="stChatMessage"] {
        border-radius: 15px; margin-bottom: 10px;
        box-shadow: 0 2px 8px rgba(0,0,0,0.05);
        border: 1px solid #eee;
    }
    
    /* Thanh Action Bar dÆ°á»›i má»—i tin nháº¯n */
    .action-bar { display: flex; gap: 5px; margin-top: 10px; flex-wrap: wrap; }
    .action-btn { 
        background: #f0f2f5; border: none; border-radius: 8px; 
        padding: 5px 12px; font-size: 12px; cursor: pointer;
    }

    /* Fixed Input Bar cho Mobile */
    .stChatInputContainer { position: fixed; bottom: 0; left: 0; right: 0; background: white; z-index: 1000; padding: 10px 5%; }

    /* NÃºt báº¥m ná»•i báº­t */
    button[kind="primary"] { background-color: #007bff !important; border: none; }
    button[kind="secondary"] { background-color: #6c757d !important; }

    /* CSS cho Suggestion Chips */
    .chip {
        display: inline-block; padding: 5px 15px; margin: 5px;
        background: #e1f5fe; border: 1px solid #01579b;
        border-radius: 20px; font-size: 13px; cursor: pointer;
    }
    </style>
    """, unsafe_allow_html=True)

# --- 2. JAVASCRIPT: ÄIá»€U KHIá»‚N NÃ‚NG CAO ---
def get_js_tools(text, speed, lang):
    clean_text = text.replace('"', "'").replace('\n', ' ')
    return f"""
    <script>
    // HÃ m Ä‘á»c
    window.speak = () => {{
        window.speechSynthesis.cancel();
        var msg = new SpeechSynthesisUtterance("{clean_text}");
        msg.lang = "{lang}"; msg.rate = {speed};
        window.speechSynthesis.speak(msg);
    }};
    // HÃ m copy
    window.copyText = () => {{
        navigator.clipboard.writeText("{clean_text}");
        alert("ÄÃ£ sao chÃ©p vÃ o bá»™ nhá»› táº¡m!");
    }};
    </script>
    """

# --- 3. KHá»I Táº O STATE & API ---
if "messages" not in st.session_state: st.session_state.messages = []
if "voice_draft" not in st.session_state: st.session_state.voice_draft = ""
if "theme" not in st.session_state: st.session_state.theme = "Light"

client = OpenAI(api_key=st.secrets["GROQ_API_KEY"], base_url="https://api.groq.com/openai/v1")

# --- 4. HÃ€M Xá»¬ LÃ NGÃ”N NGá»® CHIáº¾M Æ¯U THáº¾ ---
def get_dominant_lang(text):
    try:
        # Láº¥y danh sÃ¡ch cÃ¡c ngÃ´n ngá»¯ Ä‘Æ°á»£c nháº­n diá»‡n
        langs = detect_langs(text)
        # Láº¥y ngÃ´n ngá»¯ cÃ³ xÃ¡c suáº¥t cao nháº¥t
        main_lang = langs[0].lang
        mapping = {"vi": "vi-VN", "en": "en-US", "ja": "ja-JP", "ko": "ko-KR", "fr": "fr-FR", "zh": "zh-CN"}
        return mapping.get(main_lang, "vi-VN")
    except: return "vi-VN"

def get_audio_download(text, lang_code):
    try:
        tts = gTTS(text=text, lang=lang_code.split('-')[0])
        fp = BytesIO(); tts.write_to_fp(fp); b64 = base64.b64encode(fp.getvalue()).decode()
        return f'data:audio/mp3;base64,{b64}'
    except: return ""

# --- 5. SIDEBAR: SIÃŠU ÄIá»€U KHIá»‚N ---
with st.sidebar:
    st.title("âš¡ Nexus Terminal")
    st.session_state.v_speed = st.slider("Tá»‘c Ä‘á»™ Ä‘á»c", 0.5, 2.0, 1.1)
    
    col_stop, col_clear = st.columns(2)
    with col_stop:
        if st.button("ğŸ›‘ Dá»«ng Ä‘á»c", use_container_width=True):
            st.components.v1.html("<script>window.speechSynthesis.cancel();</script>", height=0)
    with col_clear:
        if st.button("ğŸ—‘ï¸ Reset", use_container_width=True):
            st.session_state.messages = []; st.rerun()

    st.divider()
    st.session_state.auto_read = st.toggle("Tá»± Ä‘á»™ng phÃ¡t Ã¢m thanh", value=True)
    hands_free = st.toggle("ğŸ™ï¸ Ráº£nh tay (NÃ³i & Gá»­i)", value=False)
    
    st.subheader("ğŸ“¤ Xuáº¥t dá»¯ liá»‡u")
    history_text = "\n".join([f"{m['role'].upper()}: {m['content']}" for m in st.session_state.messages])
    st.download_button("ğŸ“¥ Táº£i File .txt", data=history_text, file_name="chat_nexus.txt", use_container_width=True)
    if st.button("ğŸ“± Táº¡o mÃ£ QR", use_container_width=True):
        qr = qrcode.make(history_text[:500]); buf = BytesIO(); qr.save(buf, format="PNG")
        st.image(buf)

# --- 6. GIAO DIá»†N CHÃNH ---
st.title("AI Nexus Omni âš¡")

# Gá»£i Ã½ nhanh (Quick Chips)
suggestions = ["TÃ³m táº¯t Ä‘oáº¡n chat", "Dá»‹ch sang tiáº¿ng Anh", "Giáº£i thÃ­ch chi tiáº¿t hÆ¡n", "Viáº¿t code vÃ­ dá»¥"]
cols_suggest = st.columns(len(suggestions))
for i, suggest in enumerate(suggestions):
    if cols_suggest[i].button(suggest, key=f"sug_{i}"):
        st.session_state.messages.append({"role": "user", "content": suggest})
        # Logic xá»­ lÃ½ AI sáº½ Ä‘Æ°á»£c trigger á»Ÿ dÆ°á»›i

# HIá»‚N THá»Š CHAT
for i, m in enumerate(st.session_state.messages):
    with st.chat_message(m["role"]):
        st.markdown(m["content"])
        if m["role"] == "assistant":
            # ACTION BAR
            lang = get_dominant_lang(m["content"])
            audio_data = get_audio_download(m["content"], lang)
            
            col1, col2, col3, col4 = st.columns([1,1,1,1])
            with col1:
                if st.button("ğŸ”Š Äá»c", key=f"speak_{i}"):
                    st.components.v1.html(get_js_tools(m["content"], st.session_state.v_speed, lang) + "<script>window.speak();</script>", height=0)
            with col2:
                st.markdown(f'<a href="{audio_data}" download="voice_{i}.mp3" style="text-decoration:none;"><button style="width:100%; border-radius:10px; border:1px solid #ddd; cursor:pointer;">ğŸ“¥ Táº£i</button></a>', unsafe_allow_html=True)
            with col3:
                if st.button("ğŸ“‹ Copy", key=f"copy_{i}"):
                    st.components.v1.html(get_js_tools(m["content"], 1, lang) + "<script>window.copyText();</script>", height=0)
            with col4:
                if st.button("ğŸŒ Dá»‹ch", key=f"trans_{i}"):
                    st.info("TÃ­nh nÄƒng dá»‹ch Ä‘ang Ä‘Æ°á»£c nÃ¢ng cáº¥p...")

# --- 7. INPUT AREA (ÄA PHÆ¯Æ NG THá»¨C) ---
st.write("<br><br><br><br>", unsafe_allow_html=True)

def process_ai_logic(text):
    st.session_state.messages.append({"role": "user", "content": text})
    with st.chat_message("assistant"):
        p = st.empty(); full = ""
        res = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages],
            stream=True
        )
        for chunk in res:
            if chunk.choices[0].delta.content:
                full += chunk.choices[0].delta.content
                p.markdown(full + "â–Œ")
        p.markdown(full)
        st.session_state.messages.append({"role": "assistant", "content": full})
        if st.session_state.auto_read:
            lang = get_dominant_lang(full)
            st.components.v1.html(get_js_tools(full, st.session_state.v_speed, lang) + "<script>window.speak();</script>", height=0)

# Nháº­p liá»‡u giá»ng nÃ³i
if st.session_state.voice_draft and not hands_free:
    with st.container():
        st.info("ğŸ“ Báº£n nhÃ¡p:")
        v_text = st.text_area("", value=st.session_state.voice_draft)
        if st.button("ğŸš€ Gá»­i ngay", use_container_width=True):
            st.session_state.voice_draft = ""; process_ai_logic(v_text); st.rerun()
else:
    c_mic, c_in = st.columns([1, 6])
    with c_mic:
        audio = mic_recorder(start_prompt="ğŸ¤", stop_prompt="â¹ï¸", key='mic_v9')
    if audio:
        with st.spinner(""):
            transcript = client.audio.transcriptions.create(
                model="whisper-large-v3-turbo", file=("v.wav", audio['bytes'])
            )
            if hands_free: process_ai_logic(transcript.text); st.rerun()
            else: st.session_state.voice_draft = transcript.text; st.rerun()

    prompt = st.chat_input("Há»i tÃ´i báº¥t cá»© Ä‘iá»u gÃ¬...")
    if prompt:
        process_ai_logic(prompt); st.rerun()
