import streamlit as st
from openai import OpenAI
from gtts import gTTS
from io import BytesIO
from streamlit_mic_recorder import mic_recorder
import qrcode
import base64
from langdetect import detect

# --- 1. Cáº¤U HÃŒNH UI SIÃŠU Cáº¤P ---
st.set_page_config(page_title="Nexus Context Master", layout="wide", page_icon="ğŸ§ ")

st.markdown("""
    <style>
    .stApp { background-color: #ffffff; }
    /* Bong bÃ³ng chat tinh táº¿ */
    div[data-testid="stChatMessage"] {
        border-radius: 15px; margin-bottom: 12px;
        border: 1px solid #f0f0f0; box-shadow: 0 4px 12px rgba(0,0,0,0.03);
    }
    /* Thanh Suggestion Chips */
    .chip-container { display: flex; flex-wrap: wrap; gap: 8px; margin: 10px 0; }
    .stButton button { border-radius: 20px !important; transition: 0.2s; }
    /* Input dÃ­nh Ä‘Ã¡y cho Mobile */
    .stChatInputContainer { position: fixed; bottom: 0; background: white; z-index: 1000; padding: 10px 0; }
    @media (max-width: 600px) { .stChatInputContainer { padding: 5px; } }
    </style>
    """, unsafe_allow_html=True)

# --- 2. CÃ”NG Cá»¤ Há»– TRá»¢ (JS & NGÃ”N NGá»®) ---
def speak_js(text, speed, lang):
    clean = text.replace('"', "'").replace('\n', ' ')
    return f"<script>window.speechSynthesis.cancel(); var m=new SpeechSynthesisUtterance('{clean}'); m.lang='{lang}'; m.rate={speed}; window.speechSynthesis.speak(m);</script>"

def get_lang_full(text):
    try:
        l = detect(text)
        mapping = {"vi":"vi-VN", "en":"en-US", "ja":"ja-JP", "ko":"ko-KR", "fr":"fr-FR", "zh":"zh-CN"}
        return mapping.get(l, "vi-VN")
    except: return "vi-VN"

# --- 3. KHá»I Táº O STATE ---
if "messages" not in st.session_state: st.session_state.messages = []
if "suggestions" not in st.session_state: st.session_state.suggestions = ["ChÃ o buá»•i sÃ¡ng!", "Ká»ƒ tÃ´i nghe má»™t chuyá»‡n vui", "Dá»‹ch giÃºp tÃ´i má»™t cÃ¢u"]
if "voice_draft" not in st.session_state: st.session_state.voice_draft = ""

client = OpenAI(api_key=st.secrets["GROQ_API_KEY"], base_url="https://api.groq.com/openai/v1")

# --- 4. HÃ€M Xá»¬ LÃ AI VÃ€ Gá»¢I Ã Äá»˜NG ---
def process_ai(user_input):
    st.session_state.messages.append({"role": "user", "content": user_input})
    
    # 1. PhÃ¡t hiá»‡n ngÃ´n ngá»¯ Ä‘áº§u vÃ o Ä‘á»ƒ Ã©p AI tráº£ lá»i tÆ°Æ¡ng á»©ng
    user_lang = get_lang_full(user_input)
    
    with st.chat_message("assistant"):
        p = st.empty(); full = ""
        # Gá»i Groq cho pháº£n há»“i chÃ­nh
        res = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "system", "content": f"Respond primarily in the language detected: {user_lang}"}] + 
                     [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages],
            stream=True
        )
        for chunk in res:
            if chunk.choices[0].delta.content:
                full += chunk.choices[0].delta.content
                p.markdown(full + "â–Œ")
        p.markdown(full)
        st.session_state.messages.append({"role": "assistant", "content": full})
        
        # 2. Tá»± Ä‘á»™ng Ä‘á»c Ä‘Ãºng ngÃ´n ngá»¯
        if st.session_state.get("auto_read", True):
            st.components.v1.html(speak_js(full, st.session_state.get("v_speed", 1.1), user_lang), height=0)

        # 3. Táº O Gá»¢I Ã Äá»˜NG (Dá»±a trÃªn ngá»¯ cáº£nh vá»«a tráº£ lá»i)
        try:
            sug_res = client.chat.completions.create(
                model="llama-3.1-8b-instant", # Model nhá» Ä‘á»ƒ cá»±c nhanh
                messages=[{"role": "user", "content": f"Dá»±a trÃªn cÃ¢u tráº£ lá»i nÃ y: '{full[:200]}', hÃ£y Ä‘Æ°a ra 3 cÃ¢u há»i gá»£i Ã½ ngáº¯n gá»n (dÆ°á»›i 6 tá»«) mÃ  ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ muá»‘n há»i tiáº¿p. NgÃ´n ngá»¯: {user_lang}. Chá»‰ tráº£ vá» cÃ¡c cÃ¢u há»i cÃ¡ch nhau báº±ng dáº¥u pháº©y."}]
            )
            new_sugs = sug_res.choices[0].message.content.split(',')
            st.session_state.suggestions = [s.strip() for s in new_sugs if s.strip()][:3]
        except: pass

# --- 5. SIDEBAR: ÄIá»€U KHIá»‚N Tá»”NG Lá»°C ---
with st.sidebar:
    st.title("ğŸ›¡ï¸ Nexus v10")
    st.session_state.v_speed = st.slider("Tá»‘c Ä‘á»™ giá»ng Ä‘á»c", 0.5, 2.0, 1.1)
    if st.button("ğŸ›‘ Dá»ªNG Äá»ŒC", type="primary", use_container_width=True):
        st.components.v1.html("<script>window.speechSynthesis.cancel();</script>", height=0)
    
    st.divider()
    st.session_state.auto_read = st.toggle("Tá»± Ä‘á»™ng Ä‘á»c", value=True)
    hands_free = st.toggle("ğŸ™ï¸ Ráº£nh tay (NÃ³i & Gá»­i)", value=False)
    
    with st.expander("ğŸ“‚ Quáº£n lÃ½ & Xuáº¥t báº£n"):
        hist = "\n".join([f"{m['role'].upper()}: {m['content']}" for m in st.session_state.messages])
        st.download_button("ğŸ“¥ Táº£i lá»‹ch sá»­ .txt", data=hist, file_name="chat.txt", use_container_width=True)
        if st.button("ğŸ“± Táº¡o mÃ£ QR", use_container_width=True):
            qr = qrcode.make(hist[:600]); buf = BytesIO(); qr.save(buf, format="PNG"); st.image(buf)
        if st.button("ğŸ—‘ï¸ XÃ³a sáº¡ch chat", use_container_width=True):
            st.session_state.messages = []; st.rerun()

# --- 6. GIAO DIá»†N CHÃNH ---
st.title("AI Nexus: Context Master ğŸ§ ")

# HIá»‚N THá»Š CHAT
for i, m in enumerate(st.session_state.messages):
    with st.chat_message(m["role"]):
        st.markdown(m["content"])
        if m["role"] == "assistant":
            # Action Bar cho tá»«ng tin nháº¯n
            c1, c2, c3 = st.columns([1,1,1])
            with c1:
                if st.button("ğŸ”Š Nghe láº¡i", key=f"r_{i}"):
                    st.components.v1.html(speak_js(m["content"], st.session_state.v_speed, get_lang_full(m["content"])), height=0)
            with c2:
                # Táº£i mp3
                try:
                    tts = gTTS(text=m["content"][:200], lang=get_lang_full(m["content"]).split('-')[0])
                    b = BytesIO(); tts.write_to_fp(b); b64 = base64.b64encode(b.getvalue()).decode()
                    st.markdown(f'<a href="data:audio/mp3;base64,{b64}" download="voice.mp3"><button style="width:100%; border-radius:15px; border:1px solid #ddd; padding:5px;">ğŸ“¥ Táº£i</button></a>', unsafe_allow_html=True)
                except: pass
            with c3:
                if st.button("ğŸ“‹ Copy", key=f"cp_{i}"):
                    st.toast("ÄÃ£ sao chÃ©p!") # Giáº£n lÆ°á»£c copy cho nhanh

# Gá»¢I Ã Äá»˜NG (DÆ¯á»šI PHáº¢N Há»’I Má»šI NHáº¤T)
st.write("---")
st.caption("ğŸ’¡ Gá»£i Ã½ cho báº¡n:")
cols = st.columns(len(st.session_state.suggestions))
for idx, sug in enumerate(st.session_state.suggestions):
    if cols[idx].button(sug, key=f"sug_btn_{idx}", use_container_width=True):
        process_ai(sug)
        st.rerun()

# --- 7. NHáº¬P LIá»†U ---
st.write("<br><br><br><br>", unsafe_allow_html=True)

if st.session_state.voice_draft and not hands_free:
    with st.container():
        st.info("ğŸ™ï¸ Chá»‰nh sá»­a giá»ng nÃ³i:")
        txt = st.text_area("", value=st.session_state.voice_draft, height=80)
        ca, cb = st.columns(2)
        if ca.button("ğŸš€ Gá»¬I", use_container_width=True):
            st.session_state.voice_draft = ""; process_ai(txt); st.rerun()
        if cb.button("ğŸ—‘ï¸ Há»¦Y", use_container_width=True):
            st.session_state.voice_draft = ""; st.rerun()
else:
    c_m, c_i = st.columns([1, 6])
    with c_m:
        audio = mic_recorder(start_prompt="ğŸ¤", stop_prompt="â¹ï¸", key='mic_v10')
    if audio:
        with st.spinner(""):
            transcript = client.audio.transcriptions.create(model="whisper-large-v3-turbo", file=("v.wav", audio['bytes']))
            if hands_free: process_ai(transcript.text); st.rerun()
            else: st.session_state.voice_draft = transcript.text; st.rerun()

    inp = st.chat_input("Há»i tÃ´i báº¥t cá»© Ä‘iá»u gÃ¬...")
    if inp:
        process_ai(inp); st.rerun()
