import streamlit as st
from openai import OpenAI
from streamlit_mic_recorder import mic_recorder
import qrcode
import json
from io import BytesIO

# --- 1. GIAO DIá»†N HIá»†N Äáº I & CHá»NG DÃNH ---
st.set_page_config(page_title="Nexus Apex v27", layout="wide", page_icon="ğŸš€")

st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Lexend:wght@300;400;600&display=swap');
    html, body, [class*="css"] { font-family: 'Lexend', sans-serif; }

    /* NÃºt gá»£i Ã½ chuyÃªn nghiá»‡p: Tá»± Ä‘á»™ng xuá»‘ng hÃ ng, khÃ´ng dÃ­nh nhau */
    .stButton > button {
        border-radius: 20px !important;
        font-weight: 500 !important;
        padding: 10px 20px !important;
        border: 1px solid #e0e0e0 !important;
        background: white !important;
        color: #333 !important;
        transition: all 0.3s ease;
    }
    .stButton > button:hover {
        border-color: #FF4B4B !important;
        color: #FF4B4B !important;
        box-shadow: 0 4px 12px rgba(255, 75, 75, 0.1);
    }

    /* Báº£ng nhiá»‡m vá»¥ ná»•i báº­t */
    .mission-box {
        background: #1E1E1E;
        color: #00FFCC;
        padding: 20px;
        border-radius: 15px;
        border-left: 10px solid #00FFCC;
        margin-bottom: 20px;
    }
    
    /* Hiá»‡u á»©ng chá»‰ dáº«n */
    .pointer { color: #FF4B4B; font-weight: bold; animation: pulse 1s infinite; }
    @keyframes pulse { 0% { opacity: 1; } 50% { opacity: 0.5; } 100% { opacity: 1; } }
    </style>
    """, unsafe_allow_html=True)

# --- 2. KHá»I Táº O STATE ---
for key in ['messages', 'suggestions', 'guide_step', 'v_speed', 'is_speaking']:
    if key not in st.session_state:
        defaults = {'messages': [], 'suggestions': [], 'guide_step': 0, 'v_speed': 1.0, 'is_speaking': False}
        st.session_state[key] = defaults[key]

client = OpenAI(api_key=st.secrets["GROQ_API_KEY"], base_url="https://api.groq.com/openai/v1")

# --- 3. HÃ€M ÄIá»€U KHIá»‚N GIá»ŒNG NÃ“I (JAVASCRIPT) ---
def voice_ctrl(text, action="speak"):
    if action == "speak":
        clean_text = text.replace('"', "'").replace('\n', ' ')
        js = f"""
        <script>
        window.speechSynthesis.cancel();
        var msg = new SpeechSynthesisUtterance("{clean_text}");
        msg.lang = 'vi-VN';
        msg.rate = {st.session_state.v_speed};
        window.speechSynthesis.speak(msg);
        </script>
        """
    else:
        js = "<script>window.speechSynthesis.cancel();</script>"
    st.components.v1.html(js, height=0)

# --- 4. Xá»¬ LÃ AI ---
def process_ai(user_input):
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("assistant"):
        p = st.empty(); full = ""
        res = client.chat.completions.create(model="llama-3.3-70b-versatile", messages=[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages], stream=True)
        for chunk in res:
            if chunk.choices[0].delta.content:
                full += chunk.choices[0].delta.content
                p.markdown(full + "â–Œ")
        p.markdown(full)
        st.session_state.messages.append({"role": "assistant", "content": full})
        
        # Gá»£i Ã½ Ä‘á»™t phÃ¡: TÃ¡ch báº¡ch rÃµ rÃ ng
        try:
            s_res = client.chat.completions.create(model="llama-3.1-8b-instant", messages=[{"role": "user", "content": f"Táº¡o 3 cÃ¢u há»i gá»£i Ã½ ngáº¯n gá»n báº±ng tiáº¿ng Viá»‡t tá»«: {full[:50]}"}])
            st.session_state.suggestions = [s.strip() for s in s_res.choices[0].message.content.split('\n') if len(s) > 5][:3]
        except: pass

        if st.session_state.guide_step == 1: st.session_state.guide_step = 2
        voice_ctrl(full) # Tá»± Ä‘á»™ng Ä‘á»c
        st.rerun()

# --- 5. SIDEBAR: ÄIá»€U KHIá»‚N Tá»I THÆ¯á»¢NG ---
with st.sidebar:
    st.title("Nexus Apex ğŸ›¡ï¸")
    
    if st.session_state.guide_step > 0:
        st.markdown(f"""<div class="mission-box">
            <small>NHIá»†M Vá»¤ {st.session_state.guide_step}/4</small><br>
            <b>{["","Gá»­i lá»i chÃ o","Thá»­ Nghe & Dá»«ng","Báº¥m Gá»£i Ã½","Quáº£n lÃ½ File"][st.session_state.guide_step]}</b>
        </div>""", unsafe_allow_html=True)

    st.subheader("ğŸ”Š Äiá»u khiá»ƒn giá»ng nÃ³i")
    st.session_state.v_speed = st.slider("Tá»‘c Ä‘á»™ Ä‘á»c", 0.5, 2.0, 1.0)
    if st.button("ğŸ›‘ Dá»ªNG Äá»ŒC NGAY", use_container_width=True, type="primary"):
        voice_ctrl("", "stop")
    
    st.divider()
    st.subheader("ğŸ“‚ Dá»¯ liá»‡u")
    with st.expander("Nháº­p/Xuáº¥t File JSON"):
        st.download_button("ğŸ“¤ Xuáº¥t JSON", data=json.dumps(st.session_state.messages), file_name="chat.json", use_container_width=True)
        up = st.file_uploader("ğŸ“¥ Nháº­p JSON", type="json")
        if up and st.button("ğŸ”„ KhÃ´i phá»¥c"):
            st.session_state.messages = json.loads(up.getvalue().decode("utf-8"))
            st.rerun()

# --- 6. GIAO DIá»†N CHÃNH ---
st.title("Há»‡ thá»‘ng Trá»£ lÃ½ Nexus v27")

if st.session_state.guide_step == 0 and not st.session_state.messages:
    if st.button("âœ¨ Báº®T Äáº¦U HÆ¯á»šNG DáºªN"):
        st.session_state.guide_step = 1; st.rerun()

# HIá»‚N THá»Š CHAT
for i, m in enumerate(st.session_state.messages):
    with st.chat_message(m["role"]):
        st.markdown(m["content"])
        if m["role"] == "assistant":
            c1, c2, c3, _ = st.columns([1, 1, 1, 4])
            with c1: 
                if st.button("ğŸ”Š Äá»c", key=f"read_{i}"):
                    voice_ctrl(m["content"])
                    if st.session_state.guide_step == 2: st.session_state.guide_step = 3; st.rerun()
            with c2:
                if st.button("ğŸ“± QR", key=f"qr_{i}"):
                    qr = qrcode.make(m["content"][:200]); buf = BytesIO(); qr.save(buf, format="PNG"); st.image(buf, width=150)
            with c3:
                # NÃºt dá»«ng Ä‘á»c ngay táº¡i dÃ²ng chat
                if st.button("ğŸ”‡ Dá»«ng", key=f"stop_{i}"):
                    voice_ctrl("", "stop")

# Gá»¢I Ã Äá»˜T PHÃ (CHá»NG DÃNH NHAU)
if st.session_state.suggestions:
    st.write("---")
    st.caption("ğŸ’¡ Gá»£i Ã½ tiáº¿p theo:")
    # Chia cá»™t Ä‘á»ƒ cÃ¡c nÃºt khÃ´ng bao giá» dÃ­nh nhau
    cols = st.columns(len(st.session_state.suggestions))
    for idx, sug in enumerate(st.session_state.suggestions):
        with cols[idx]:
            if st.button(sug, key=f"s_{idx}", use_container_width=True):
                if st.session_state.guide_step == 3: st.session_state.guide_step = 4
                process_ai(sug); st.rerun()

# INPUT CHÃNH
st.write("<br><br><br>", unsafe_allow_html=True)
with st.container():
    c1, c2 = st.columns([1, 8])
    with c1:
        aud = mic_recorder(start_prompt="ğŸ¤", stop_prompt="â¹ï¸", key='mic_v27')
        if aud:
            trans = client.audio.transcriptions.create(model="whisper-large-v3-turbo", file=("v.wav", aud['bytes']))
            process_ai(trans.text); st.rerun()
    with c2:
        if st.session_state.guide_step == 1: st.markdown('<p class="pointer">ğŸ‘‡ Báº¯t Ä‘áº§u báº±ng cÃ¡ch nháº­p tin nháº¯n!</p>', unsafe_allow_html=True)
        inp = st.chat_input("Há»i Nexus...")
        if inp: process_ai(inp); st.rerun()
