import streamlit as st
from openai import OpenAI
from gtts import gTTS
from io import BytesIO
import qrcode
from streamlit_mic_recorder import mic_recorder

# --- 1. Cáº¤U HÃŒNH GIAO DIá»†N CHUáº¨N CHAT ---
st.set_page_config(page_title="AI Live Pro v3", layout="wide", page_icon="ğŸ™ï¸")

# CSS Ä‘á»ƒ cá»‘ Ä‘á»‹nh khung chat vÃ  lÃ m Ä‘áº¹p giao diá»‡n
st.markdown("""
    <style>
    .stChatFloatingInputContainer { bottom: 20px; }
    .main { background-color: #ffffff; }
    div[data-testid="stVerticalBlock"] > div:has(div.stButton) {
        display: flex; align-items: center;
    }
    </style>
    """, unsafe_allow_html=True)

GROQ_API_KEY = st.secrets.get("GROQ_API_KEY", "")

if "messages" not in st.session_state: st.session_state.messages = []
if "speech_text" not in st.session_state: st.session_state.speech_text = ""
if "interrupt" not in st.session_state: st.session_state.interrupt = False

def text_to_speech(text, speed=1.0):
    tts = gTTS(text=text, lang='vi')
    fp = BytesIO()
    tts.write_to_fp(fp)
    return fp.getvalue()

# --- 2. SIDEBAR QUáº¢N LÃ ---
with st.sidebar:
    st.title("ğŸ™ï¸ Cáº¥u hÃ¬nh Live")
    speed = st.slider("Tá»‘c Ä‘á»™ AI Ä‘á»c", 0.5, 2.0, 1.0, 0.1)
    st.divider()
    if st.button("ğŸ›‘ NGáº®T Lá»œI CHATBOT"):
        st.session_state.interrupt = True
        st.rerun()
    if st.button("ğŸ—‘ï¸ XÃ³a lá»‹ch sá»­"):
        st.session_state.messages = []
        st.rerun()

# --- 3. HIá»‚N THá»Š CHAT (Tá»° Äá»˜NG CUá»˜N) ---
st.title("ğŸ¤– Trá»£ lÃ½ ThÃ´ng minh")

# Container hiá»ƒn thá»‹ ná»™i dung chat Ä‘á»ƒ khÃ´ng bá»‹ Ä‘Ã¨ bá»Ÿi thanh nháº­p liá»‡u
chat_placeholder = st.container()
with chat_placeholder:
    for i, m in enumerate(st.session_state.messages):
        with st.chat_message(m["role"]):
            st.markdown(m["content"])
            if m["role"] == "assistant":
                st.audio(text_to_speech(m["content"], speed), format="audio/mp3")

# --- 4. KHU Vá»°C NHáº¬P LIá»†U THÃ”NG MINH ---
# Pháº§n nÃ y xá»­ lÃ½ viá»‡c "Dá»‹ch giá»ng nÃ³i xong hiá»‡n lÃªn Ä‘á»ƒ sá»­a"
st.write("---")
col_mic, col_status = st.columns([1, 5])
with col_mic:
    audio_record = mic_recorder(start_prompt="ğŸ¤ NÃ³i", stop_prompt="âœ… Dá»‹ch", key='mic_v3')

if audio_record:
    with st.spinner("Äang khá»­ nhiá»…u vÃ  dá»‹ch..."):
        client = OpenAI(api_key=GROQ_API_KEY, base_url="https://api.groq.com/openai/v1")
        with open("temp.wav", "wb") as f:
            f.write(audio_record['bytes'])
        with open("temp.wav", "rb") as af:
            transcript = client.audio.transcriptions.create(
                model="whisper-large-v3", 
                file=af, 
                language="vi"
            )
        # LÆ°u vÃ o session Ä‘á»ƒ hiá»‡n lÃªn chat_input
        st.session_state.speech_text = transcript.text
        st.rerun()

# Ã” NHáº¬P LIá»†U CHÃNH: Nháº¥n Enter lÃ  gá»­i, tá»± Ä‘á»™ng xÃ³a chá»¯ sau khi gá»­i
# Náº¿u cÃ³ vÄƒn báº£n tá»« giá»ng nÃ³i, nÃ³ sáº½ hiá»‡n sáºµn á»Ÿ Ä‘Ã¢y Ä‘á»ƒ báº¡n sá»­a
prompt = st.chat_input("Nháº­p tin nháº¯n hoáº·c sá»­a ná»™i dung Ä‘Ã£ nÃ³i...", key="main_input")

# Logic gá»­i tin (há»— trá»£ cáº£ Enter vÃ  click nÃºt gá»­i cá»§a chat_input)
final_input = prompt if prompt else (None if not st.session_state.speech_text else None)

# Náº¿u ngÆ°á»i dÃ¹ng sá»­a ná»™i dung dá»‹ch hoáº·c gÃµ má»›i
if prompt:
    input_to_send = prompt
    st.session_state.speech_text = "" # XÃ³a bá»™ nhá»› Ä‘á»‡m giá»ng nÃ³i
    
    st.session_state.interrupt = False
    st.session_state.messages.append({"role": "user", "content": input_to_send})
    
    with st.chat_message("assistant"):
        res_area = st.empty()
        full_res = ""
        client = OpenAI(api_key=GROQ_API_KEY, base_url="https://api.groq.com/openai/v1")
        
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages],
            stream=True
        )
        
        for chunk in response:
            if st.session_state.interrupt: break
            if chunk.choices[0].delta.content:
                full_res += chunk.choices[0].delta.content
                res_area.markdown(full_res + "â–Œ")
        
        res_area.markdown(full_res)
        st.session_state.messages.append({"role": "assistant", "content": full_res})
        st.rerun()

# Hiá»ƒn thá»‹ thÃ´ng bÃ¡o náº¿u cÃ³ vÄƒn báº£n Ä‘ang chá» gá»­i tá»« Mic
if st.session_state.speech_text:
    st.info(f"ğŸ’¡ Ná»™i dung vá»«a dá»‹ch: **{st.session_state.speech_text}**\n\n(HÃ£y copy vÃ o Ã´ chat hoáº·c gÃµ Ä‘Ã¨ Ä‘á»ƒ sá»­a trÆ°á»›c khi nháº¥n Enter)")
