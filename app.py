import streamlit as st
from openai import OpenAI
from gtts import gTTS
from io import BytesIO
from streamlit_mic_recorder import mic_recorder
import qrcode
import base64

# --- 1. Cáº¤U HÃŒNH UI SIÃŠU Cáº¤P ---
st.set_page_config(page_title="AI Nexus Ultra", layout="wide", page_icon="ğŸŒ")

# CSS Ä‘á»ƒ giao diá»‡n Ä‘áº¹p trÃªn má»i thiáº¿t bá»‹
st.markdown("""
    <style>
    /* Tá»•ng thá»ƒ giao diá»‡n sÃ¡ng, tá»‘i giáº£n */
    .stApp { background-color: #f0f2f5; }
    
    /* Bong bÃ³ng chat chuyÃªn nghiá»‡p */
    div[data-testid="stChatMessage"] {
        border-radius: 20px;
        padding: 15px;
        margin-bottom: 10px;
        max-width: 85%;
        box-shadow: 0 4px 6px rgba(0,0,0,0.05);
    }
    
    /* Thanh nháº­p liá»‡u cá»‘ Ä‘á»‹nh á»Ÿ Ä‘Ã¡y */
    .stChatInputContainer {
        position: fixed;
        bottom: 10px;
        left: 0;
        right: 0;
        z-index: 1000;
        padding: 0 10%;
    }

    /* NÃºt báº¥m bo trÃ²n */
    .stButton button {
        border-radius: 30px !important;
        transition: 0.3s;
    }

    /* áº¨n bá»›t cÃ¡c thÃ nh pháº§n thá»«a trÃªn Mobile */
    @media (max-width: 600px) {
        .stChatInputContainer { padding: 0 2%; }
        div[data-testid="stChatMessage"] { max-width: 95%; }
        .stTitle { font-size: 1.5rem !important; }
    }
    </style>
    """, unsafe_allow_html=True)

# --- 2. JAVASCRIPT: Äá»ŒC GIá»ŒNG NÃ“I Tá»¨C THÃŒ ---
def speak_js(text, speed):
    clean_text = text.replace('"', "'").replace('\n', ' ')
    return f"""
    <script>
    window.speechSynthesis.cancel();
    var msg = new SpeechSynthesisUtterance("{clean_text}");
    msg.lang = 'vi-VN';
    msg.rate = {speed};
    window.speechSynthesis.speak(msg);
    </script>
    """

# --- 3. KHá»I Táº O STATE & API ---
if "messages" not in st.session_state: st.session_state.messages = []
if "voice_draft" not in st.session_state: st.session_state.voice_draft = ""

try:
    client = OpenAI(api_key=st.secrets["GROQ_API_KEY"], base_url="https://api.groq.com/openai/v1")
except:
    st.error("âš ï¸ Cáº§n GROQ_API_KEY trong Secrets!")
    st.stop()

# --- 4. CÃ”NG Cá»¤ Táº¢I VOICE (gTTS cho Download) ---
def get_audio_download_link(text):
    tts = gTTS(text=text, lang='vi')
    fp = BytesIO()
    tts.write_to_fp(fp)
    b64 = base64.b64encode(fp.getvalue()).decode()
    return f'<a href="data:audio/mp3;base64,{b64}" download="ai_voice.mp3" style="text-decoration:none;"><button style="background-color:#4CAF50; border:none; color:white; padding:5px 15px; border-radius:15px; cursor:pointer;">ğŸ“¥ Táº£i Voice (.mp3)</button></a>'

def process_ai(user_input):
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("assistant"):
        p = st.empty()
        full = ""
        res = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages],
            stream=True
        )
        for chunk in res:
            if chunk.choices[0].delta.content:
                full += chunk.choices[0].delta.content
                p.markdown(full + "â–Œ")
        p.markdown(full)
        st.session_state.messages.append({"role": "assistant", "content": full})
        if st.session_state.get("auto_read", True):
            st.components.v1.html(speak_js(full, st.session_state.get("v_speed", 1.1)), height=0)

# --- 5. SIDEBAR: QUáº¢N LÃ Dá»® LIá»†U ---
with st.sidebar:
    st.title("âš™ï¸ AI Nexus Pro")
    st.session_state.v_speed = st.slider("Tá»‘c Ä‘á»™", 0.5, 2.0, 1.1)
    st.session_state.auto_read = st.toggle("Tá»± Ä‘á»™ng Ä‘á»c", value=True)
    hands_free = st.toggle("âš¡ Ráº£nh tay (Gá»­i luÃ´n)", value=False)
    
    st.divider()
    st.subheader("ğŸ’¾ Backup & QR")
    history_txt = "\n".join([f"{m['role'].upper()}: {m['content']}" for m in st.session_state.messages])
    
    c1, c2 = st.columns(2)
    with c1:
        st.download_button("ğŸ“¤ Xuáº¥t .txt", data=history_txt, file_name="chat.txt")
    with c2:
        if st.button("ğŸ“± MÃ£ QR"):
            qr = qrcode.make(history_txt[:1000])
            buf = BytesIO()
            qr.save(buf, format="PNG")
            st.image(buf)

    uploaded = st.file_uploader("ğŸ“‚ Nháº­p lá»‹ch sá»­", type="txt")
    if uploaded:
        # Xá»­ lÃ½ nháº­p file (giáº£n lÆ°á»£c Ä‘á»ƒ nhanh)
        if st.button("ğŸ”„ KhÃ´i phá»¥c"):
            data = uploaded.getvalue().decode("utf-8")
            st.info("ÄÃ£ nháº­n file, hÃ£y refresh Ä‘á»ƒ xem káº¿t quáº£!")

    if st.button("ğŸ—‘ï¸ XÃ³a sáº¡ch"):
        st.session_state.messages = []
        st.session_state.voice_draft = ""
        st.rerun()

# --- 6. GIAO DIá»†N CHÃNH ---
st.title("AI Nexus Ultra ğŸš€")

# Hiá»ƒn thá»‹ há»™i thoáº¡i
for i, m in enumerate(st.session_state.messages):
    with st.chat_message(m["role"]):
        st.markdown(m["content"])
        if m["role"] == "assistant":
            col_a, col_b = st.columns([1, 2])
            with col_a:
                if st.button("ğŸ”Š Äá»c láº¡i", key=f"r_{i}"):
                    st.components.v1.html(speak_js(m["content"], st.session_state.v_speed), height=0)
            with col_b:
                # TÃNH NÄ‚NG Táº¢I FILE Äá»ŒC
                st.markdown(get_audio_download_link(m["content"]), unsafe_allow_html=True)

# --- 7. KHU Vá»°C NHáº¬P LIá»†U ---
st.write("<br><br><br>", unsafe_allow_html=True) # Khoáº£ng trá»‘ng cho input cá»‘ Ä‘á»‹nh

if st.session_state.voice_draft and not hands_free:
    with st.container():
        st.warning("ğŸ“ Sá»­a báº£n dá»‹ch:")
        txt = st.text_area("", value=st.session_state.voice_draft, height=80)
        ca, cb = st.columns(2)
        if ca.button("ğŸš€ Gá»¬I", use_container_width=True):
            st.session_state.voice_draft = ""
            process_ai(txt)
            st.rerun()
        if cb.button("ğŸ—‘ï¸ Há»¦Y", use_container_width=True):
            st.session_state.voice_draft = ""
            st.rerun()
else:
    c_m, c_i = st.columns([1, 8])
    with c_m:
        audio = mic_recorder(start_prompt="ğŸ¤", stop_prompt="â¹ï¸", key='mic_v6')
    
    if audio:
        with st.spinner("âš¡"):
            transcript = client.audio.transcriptions.create(
                model="whisper-large-v3-turbo", file=("v.wav", audio['bytes']), language="vi"
            )
            if hands_free:
                process_ai(transcript.text)
                st.rerun()
            else:
                st.session_state.voice_draft = transcript.text
                st.rerun()

    inp = st.chat_input("Há»i tÃ´i báº¥t cá»© Ä‘iá»u gÃ¬...")
    if inp:
        process_ai(inp)
        st.rerun()
