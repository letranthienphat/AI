import streamlit as st
from openai import OpenAI
import google.generativeai as genai
import random

# --- 1. Cáº¤U HÃŒNH Há»† THá»NG ---
st.set_page_config(page_title="Nexus OS V50.0.1.3", layout="wide")

# --- 2. Láº¤Y Dá»® LIá»†U Tá»ª SECRETS ---
# LÆ°u Ã½: Pháº£i khá»›p 100% vá»›i má»¥c Secrets báº¡n Ä‘Ã£ dÃ¡n
try:
    # ChÃºng ta dÃ¹ng get() Ä‘á»ƒ náº¿u thiáº¿u key nÃ³ sáº½ bÃ¡o lá»—i rÃµ rÃ ng hÆ¡n thay vÃ¬ sáº­p App
    GROQ_LIST = st.secrets.get("GROQ_KEYS", [])
    GEMINI_CORE_KEY = st.secrets.get("GEMINI_KEY", "")

    if not GROQ_LIST or not GEMINI_CORE_KEY:
        st.error("ðŸ†˜ Lá»—i: KhÃ´ng tÃ¬m tháº¥y GROQ_KEYS hoáº·c GEMINI_KEY trong má»¥c Secrets.")
        st.stop()

    # Cáº¥u hÃ¬nh Gemini
    genai.configure(api_key=GEMINI_CORE_KEY)
    gemini_engine = genai.GenerativeModel('gemini-1.5-flash')
except Exception as e:
    st.error(f"âŒ Lá»—i cáº¥u hÃ¬nh: {e}")
    st.stop()

# --- 3. KHá»žI Táº O Bá»˜ NHá»š ---
if 'messages' not in st.session_state:
    st.session_state.messages = []

# --- 4. HÃ€M Xá»¬ LÃ AI (Há»† THá»NG XOAY VÃ’NG Má»šI) ---
def nexus_ai_logic(chat_history):
    # Trá»™n danh sÃ¡ch key
    pool = list(GROQ_LIST)
    random.shuffle(pool)
    
    # Láº¥y 5 cÃ¢u gáº§n nháº¥t
    recent_context = chat_history[-6:]
    
    # THá»¬ Láº¦N LÆ¯á»¢T CÃC KEY TRONG POOL
    for current_key in pool:
        try:
            # KHÃ”NG DÃ™NG BIáº¾N "GROQ_API_KEY" CÅ¨ Ná»®A
            client = OpenAI(api_key=current_key, base_url="https://api.groq.com/openai/v1")
            stream = client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": m["role"], "content": m["content"]} for m in recent_context],
                stream=True
            )
            return stream, "Groq-Node"
        except Exception:
            continue # Thá»­ key tiáº¿p theo náº¿u lá»—i
            
    # Náº¾U Táº¤T Cáº¢ THáº¤T Báº I -> GEMINI
    try:
        chat = gemini_engine.start_chat(history=[])
        response = chat.send_message(chat_history[-1]["content"], stream=True)
        return response, "Gemini-Node"
    except:
        return None, None

# --- 5. GIAO DIá»†N CHAT ---
st.title("ðŸ’  Nexus Terminal V50.0.1.3")

# Hiá»ƒn thá»‹ lá»‹ch sá»­
for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# Ã” nháº­p liá»‡u
if prompt := st.chat_input("Nháº­p tin nháº¯n..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        placeholder = st.empty()
        full_response = ""
        
        result, node_type = nexus_ai_logic(st.session_state.messages)
        
        if result:
            if node_type == "Groq-Node":
                for chunk in result:
                    if chunk.choices[0].delta.content:
                        full_response += chunk.choices[0].delta.content
                        placeholder.markdown(full_response + "â–Œ")
            else: # Gemini
                for chunk in result:
                    full_response += chunk.text
                    placeholder.markdown(full_response + "â–Œ")
            
            placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            st.caption(f"âœ“ Káº¿t ná»‘i á»•n Ä‘á»‹nh qua {node_type}")
        else:
            st.error("ðŸ†˜ Há»‡ thá»‘ng quÃ¡ táº£i. Vui lÃ²ng kiá»ƒm tra láº¡i Keys hoáº·c Ä‘á»£i 1 phÃºt.")
