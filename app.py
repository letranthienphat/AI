import streamlit as st
from openai import OpenAI
from streamlit_mic_recorder import mic_recorder
import qrcode
from io import BytesIO

# --- 1. Cáº¤U HÃŒNH GIAO DIá»†N LIGHT-SPEED ---
st.set_page_config(page_title="AI Nexus God Mode", layout="wide")

st.markdown("""
    <style>
    .stApp { background-color: #F8F9FA; color: #1A1A1A; }
    .stChatMessage { background-color: white !important; border: 1px solid #EAEAEA; border-radius: 12px; box-shadow: 0 2px 4px rgba(0,0,0,0.02); }
    .stChatInputContainer { padding-bottom: 20px; }
    #MainMenu {visibility: hidden;} footer {visibility: hidden;}
    </style>
    """, unsafe_allow_html=True)

# --- 2. JAVASCRIPT: BROWSER TTS (Äá»ŒC KHÃ”NG Äá»˜ TRá»„) ---
def speak_js(text, speed):
    if not text: return ""
    clean_text = text.replace('"', "'").replace('\n', ' ')
    return f"""
    <script>
    window.speechSynthesis.cancel();
    var msg = new SpeechSynthesisUtterance("{clean_text}");
    msg.lang = 'vi-VN';
    msg.rate = {speed};
    window.speechSynthesis.speak(msg);
    </script>
    """

# --- 3. KHá»I Táº O API & SESSION (100% GROQ) ---
client = OpenAI(api_key=st.secrets["GROQ_API_KEY"], base_url="https://api.groq.com/openai/v1")

if "messages" not in st.session_state: st.session_state.messages = []
if "voice_draft" not in st.session_state: st.session_state.voice_draft = ""

# --- 4. HÃ€M Xá»¬ LÃ AI TRá»ŒNG TÃ‚M (Äáº¢M Báº¢O LUÃ”N TRáº¢ Lá»œI) ---
def get_ai_response(user_text):
    if not user_text: return
    
    # ThÃªm tin nháº¯n user
    st.session_state.messages.append({"role": "user", "content": user_text})
    
    with st.chat_message("assistant"):
        placeholder = st.empty()
        full_res = ""
        try:
            # DÃ¹ng model máº¡nh nháº¥t & nhanh nháº¥t cá»§a Groq
            stream = client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages],
                stream=True,
            )
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    full_res += chunk.choices[0].delta.content
                    placeholder.markdown(full_res + "â–Œ")
            placeholder.markdown(full_res)
            
            # LÆ°u vÃ o lá»‹ch sá»­
            st.session_state.messages.append({"role": "assistant", "content": full_res})
            
            # Tá»± Ä‘á»™ng Ä‘á»c (Browser TTS)
            if st.session_state.get("auto_read", True):
                st.components.v1.html(speak_js(full_res, st.session_state.get("v_speed", 1.0)), height=0)
        except Exception as e:
            st.error(f"Lá»—i API: {str(e)}")

# --- 5. SIDEBAR: 100 TÃNH NÄ‚NG (Gá»ŒN GÃ€NG) ---
with st.sidebar:
    st.header("âš¡ Command Center")
    st.session_state.v_speed = st.slider("Tá»‘c Ä‘á»™ Voice", 0.5, 2.0, 1.0)
    st.session_state.auto_read = st.toggle("Tá»± Ä‘á»™ng Ä‘á»c", value=True)
    
    st.divider()
    if st.button("ğŸ“„ QR & Xuáº¥t File"):
        history = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.messages])
        qr = qrcode.make(history[:1500])
        buf = BytesIO()
        qr.save(buf, format="PNG")
        st.image(buf, caption="QuÃ©t láº¥y há»™i thoáº¡i")
        st.download_button("ğŸ“¥ Táº£i file .txt", history, file_name="chat.txt")

    if st.button("ğŸ—‘ï¸ Reset Há»‡ Thá»‘ng"):
        st.session_state.messages = []
        st.session_state.voice_draft = ""
        st.rerun()

# --- 6. GIAO DIá»†N CHÃNH ---
st.title("ğŸš€ AI Nexus Speed")

# Hiá»ƒn thá»‹ lá»‹ch sá»­ chat
for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# --- 7. NHáº¬P LIá»†U (MIC & CHAT INPUT) ---
st.write("---")
c1, c2 = st.columns([1, 10])

with c1:
    audio = mic_recorder(start_prompt="ğŸ¤", stop_prompt="âœ…", key='mic_v5')

if audio:
    with st.spinner("âš¡..."):
        # Whisper Turbo - PhÃ¡ vá»¡ giá»›i háº¡n tá»‘c Ä‘á»™ giáº£i mÃ£
        transcript = client.audio.transcriptions.create(
            model="whisper-large-v3-turbo", 
            file=("audio.wav", audio['bytes']),
            language="vi"
        )
        st.session_state.voice_draft = transcript.text

# Náº¿u cÃ³ giá»ng nÃ³i vá»«a dá»‹ch xong -> Hiá»‡n khung CHá»ˆNH Sá»¬A
if st.session_state.voice_draft:
    with st.container():
        st.info(f"ğŸ™ï¸ NhÃ¡p: {st.session_state.voice_draft}")
        col_ok, col_no = st.columns(2)
        if col_ok.button("ğŸš€ Gá»¬I Báº¢N Dá»ŠCH NÃ€Y"):
            text_to_send = st.session_state.voice_draft
            st.session_state.voice_draft = ""
            get_ai_response(text_to_send)
            st.rerun()
        if col_no.button("ğŸ—‘ï¸ Há»¦Y"):
            st.session_state.voice_draft = ""
            st.rerun()

# Ã” nháº­p vÄƒn báº£n (Enter Ä‘á»ƒ gá»­i)
user_query = st.chat_input("Há»i tÃ´i báº¥t cá»© Ä‘iá»u gÃ¬...")
if user_query:
    get_ai_response(user_query)
